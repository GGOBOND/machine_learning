{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "import joblib\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(path):\n",
    "    '''\n",
    "    used for load fasta data and transformd into numpy.array format\n",
    "    '''\n",
    "    fh=open(path)\n",
    "    seq=[]\n",
    "    for line in fh:\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line.replace('\\r\\n',''))\n",
    "    fh.close()\n",
    "    matrix_data=np.array([list(e) for e in seq])\n",
    "    return matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AthMethPre_extract_one_line(data_line,gram):\n",
    "    '''\n",
    "    extract features from one line, such as one m6A sample\n",
    "    '''\n",
    "    alphabet='ACGU'\n",
    "    matrix_two=[\"\".join(e) for e in itertools.product(alphabet, repeat=gram)] # AA AU AC AG UU UC ...\n",
    "    matrix_one=[\"\".join(e) for e in itertools.product(alphabet,repeat=gram-1)]\n",
    "    Nab=np.zeros(int(pow(4,gram)))\n",
    "    NaA=np.zeros(int(pow(4,gram-1)))\n",
    "    for index,data in enumerate(data_line):\n",
    "        if \"\".join(data_line[index:index+gram]) in matrix_two and index<=len(data_line)-gram:\n",
    "                 Nab[matrix_two.index(\"\".join(data_line[index:index+gram]))]=Nab[matrix_two.index(\"\".join(data_line[index:index+gram]))]+1\n",
    "        if \"\".join(data_line[index:index+gram-1]) in matrix_one and index<=len(data_line)-gram:\n",
    "                 NaA[matrix_one.index(\"\".join(data_line[index:index+gram-1]))]=NaA[matrix_one.index(\"\".join(data_line[index:index+gram-1]))]+1\n",
    "    Nab2=copy.deepcopy(Nab)\n",
    "    for index,data in enumerate(matrix_two):\n",
    "        if Nab[index]!=0:\n",
    "            if data[0:gram-1] in matrix_one:\n",
    "                 Nab[index]=Nab[index]/NaA[matrix_one.index(data[0:gram-1])]\n",
    "    Nab2=Nab2/(len(data_line)-1)\n",
    "    one_line_result=[]\n",
    "    one_line_result.extend(Nab)\n",
    "    one_line_result.extend(Nab2)\n",
    "    return one_line_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([1,2,3])\n",
    "b=np.array([4,5,6])\n",
    "lis=[]\n",
    "lis.extend(a)\n",
    "lis.extend(b)\n",
    "print lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AthMethPre_feature_extraction(matrix_data,gram):\n",
    "    final_feature_matrix=[AthMethPre_extract_one_line(e,gram) for e in matrix_data]\n",
    "    print np.array(final_feature_matrix).shape\n",
    "    return final_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generating_csv_file(gram):\n",
    "    m6a_benchmark_dataset='/home02/chenhuangrong/m6a_data.txt'\n",
    "    matrix_data=read_fasta_file(m6a_benchmark_dataset)\n",
    "    final_feature_matrix=AthMethPre_feature_extraction(matrix_data,gram)\n",
    "    print np.array(final_feature_matrix).shape\n",
    "    pd.DataFrame(final_feature_matrix).to_csv('/home02/chenhuangrong/%dNC.csv'%(gram),header=None,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall==0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_file_num: 2614\n",
      "first_file_length: 3\n",
      "second_file_num: 2614\n",
      "second_file_length: 3\n",
      "output_file_num: 2614\n",
      "output_file_len: 6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "used to merge features\n",
    "\"\"\"\n",
    "RFH_=pd.read_csv(\"/home02/chenhuangrong/PSNP.csv\",header=None,index_col=None)#sys.argv[1])\n",
    "RFH_=RFH_.values\n",
    "RFH_=pd.DataFrame(RFH_).astype(float)\n",
    "PseDNC_=pd.read_csv(\"/home02/chenhuangrong/PSDNP_1_gap.csv\",header=None,index_col=None)\n",
    "PseDNC_=pd.DataFrame(PseDNC_).astype(float)\n",
    "print \"first_file_num:\",len(RFH_)\n",
    "print \"first_file_length:\",len(RFH_.values[0])\n",
    "print \"second_file_num:\",len(PseDNC_)\n",
    "print \"second_file_length:\",len(PseDNC_.values[0])\n",
    "RFH_PseDNC=pd.concat([RFH_,PseDNC_],axis=1)\n",
    "print \"output_file_num:\",len(RFH_PseDNC)\n",
    "print \"output_file_len:\",len(RFH_PseDNC.values[0])\n",
    "scaler=MinMaxScaler()\n",
    "RFH_PseDNC=scaler.fit_transform(np.array(RFH_PseDNC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "def generating_crossvalidation(gram):\n",
    "    print gram\n",
    "    datapath ='/home02/chenhuangrong/%dNC.csv'%(gram)\n",
    "    train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "    X = np.array(train_data)\n",
    "    Y = list(map(lambda x: 1, xrange(len(train_data) / 2)))\n",
    "    Y2 = list(map(lambda x: 0, xrange(len(train_data) / 2)))\n",
    "    Y.extend(Y2)\n",
    "    Y = np.array(Y)\n",
    "    svc = svm.SVC()\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "    clf.fit(X, Y)\n",
    "    C=clf.best_params_['C']\n",
    "    # joblib.dump(clf,'/home02/chenhuangrong/%d_gap_%d_gram.csv'%(gap,gram))\n",
    "    print clf.best_score_\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,),X,Y,cv=10,n_jobs=-1)\n",
    "    print type(y_predict)\n",
    "    y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=-1,method='predict_proba')\n",
    "    predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "    predict_save=np.array(predict_save).T\n",
    "    pd.DataFrame(predict_save).to_csv('/home02/chenhuangrong/blending_files/%d_NC.csv'%(gram),header=None,index=False)\n",
    "    ROC_AUC_area=\"%0.4f\"%cross_val_score(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=-1).mean()\n",
    "    ACC=metrics.accuracy_score(Y,y_predict)\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "    F1_Score=metrics.f1_score(Y, y_predict)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    savedata=[[['svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "    print savedata\n",
    "#     easy_excel.save(\"svm_crossvalidation\",[str(X.shape[1])],savedata,'/home02/chenhuangrong/cross_validation_frequency_%d_gram.xls'%(gram))\n",
    "    return ACC\n",
    "    # y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "    # Y=pd.DataFrame(Y)    \n",
    "    # y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "    # y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "    # pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "    # y_predict=pd.DataFrame(y_predict)\n",
    "    # y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "    # pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2614, 32)\n",
      "(2614, 32)\n",
      "2\n",
      "0.644605967865\n",
      "<type 'numpy.ndarray'>\n",
      "[[['svmC:32.0gamma:0.157490131237', 0.64460596786534052, 0.6308864265927978, 0.6970160673297628, 0.6970160673297628, 0.5921958684009181, 0.6424718167217467, 0.66230461650308992, 0.66230461650308992, 0.29081397482285709, '0.6445', 911.0, 396.0, 533.0, 774.0, 1307.0, 1307.0]]]\n",
      "(2614, 128)\n",
      "(2614, 128)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ACC_=0\n",
    "for gram in xrange(2,9):\n",
    "    generating_csv_file(gram)\n",
    "    ACC=generating_crossvalidation(gram)\n",
    "    if ACC_<ACC:\n",
    "        ACC_=ACC\n",
    "print ACC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "b=np.array([4,5,6])\n",
    "li=[a,b]\n",
    "print np.array(li).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.25 gamma: 0.157490131237\n",
      "0.931297709924\n",
      "ACC_all: 0.931297709924\n",
      "c: 0.25 gamma: 0.0701538780193\n",
      "0.935114503817\n",
      "ACC_all: 1.86641221374\n",
      "c: 0.25 gamma: 0.0701538780193\n",
      "0.912213740458\n",
      "ACC_all: 2.7786259542\n",
      "c: 0.25 gamma: 0.157490131237\n",
      "0.958015267176\n",
      "ACC_all: 3.73664122137\n",
      "c: 0.25 gamma: 0.157490131237\n",
      "0.950381679389\n",
      "ACC_all: 4.68702290076\n",
      "c: 0.25 gamma: 0.157490131237\n",
      "0.923664122137\n",
      "ACC_all: 5.6106870229\n",
      "c: 0.25 gamma: 4.0\n",
      "0.954198473282\n",
      "ACC_all: 6.56488549618\n",
      "c: 0.25 gamma: 0.157490131237\n",
      "0.942307692308\n",
      "ACC_all: 7.50719318849\n",
      "c: 0.25 gamma: 0.157490131237\n",
      "0.938461538462\n",
      "ACC_all: 8.44565472695\n",
      "c: 0.25 gamma: 0.0701538780193\n",
      "0.946153846154\n",
      "ACC_all: 9.39180857311\n",
      "['64', '\\xe6\\xad\\xa3\\xef\\xbc\\x9a1307.0\\xe8\\xb4\\x9f\\xef\\xbc\\x9a1307.0', 'svmC:0.25gamma:0.0701538780193', 0.93918085731062817, 0.9799303685180801, 0.8967116852613037, 0.8967116852613037, 0.981650029359953, 0.9381809940519183, 0.9364019521621284, 0.9364019521621284, 0.88164235079910092, 0.49011795118861479, 1172.0, 135.0, 24.0, 1283.0]\n"
     ]
    }
   ],
   "source": [
    "final_out_to_excel=[]\n",
    "row0 = [u'特征集', u'样本个数', u'分类器', u'Accuracy', u'Precision', u'Recall', u'SN', u'SP',\n",
    "                u'Gm', u'F_measure', u'F_score', u'MCC', u'ROC曲线面积', u'tp', u'fn', u'fp', u'tn']\n",
    "final_out_to_excel.append(row0) #above was used to generate xlsx format Excel file\n",
    "RNA_code='ACGU' \n",
    "interval=3 # RNA_code and interval used mix used to generate AAA AAC AAG ...\n",
    "division_num=10\n",
    "divided_num=np.float(division_num)# ten fold so the result should divided by ten\n",
    "\n",
    "\n",
    "# seq=[e.replace('U','A') for e in seq]\n",
    "# seq=[e.replace('G','C') for e in seq]\n",
    "seq=pd.read_csv('/home02/chenhuangrong/%d_gap_%d_gram.csv'%(gap,gram),header=None,index_col=False)\n",
    "seq=seq.values\n",
    "\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "\n",
    "\n",
    "\n",
    "#define variable to save data which will be saved later --- begining\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "#define variable to save data which will be saved later --- end\n",
    "\n",
    "\n",
    "#shuffle the data of positive and negative begining\n",
    "kf = KFold(n_splits=division_num,shuffle=True)  # positive and negative samples will be shuffled \n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "#shuffle the data of positive and negative end\n",
    "\n",
    "\n",
    "    #generate train and test data begining\n",
    "    X_train = np.array(positive_negative_x_train)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(X_train) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(X_train) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(positive_negative_y_train)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(X_test) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(X_test) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test = np.array(Y_test)\n",
    "    #generate train and test data end\n",
    "\n",
    "    \n",
    "    # training model and optimized parameters of C and gamma begining\n",
    "    svc = svm.SVC(probability=True)\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # training model and optimized parameters of C and gamma end\n",
    "    \n",
    "    \n",
    "    #print best C and gamma begining\n",
    "    C=clf.best_params_['C']\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print 'c:',C,'gamma:',gamma\n",
    "    #print best C and gamma end\n",
    "    \n",
    "    \n",
    "    #getting predict probability and predict label begining\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    #getting predict probability and predict label begining\n",
    "\n",
    "    #the process of generating  usefule data begining\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "    #the process of generating  usefule data end\n",
    "    \n",
    "#the process of save  data to disk begining   \n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "# pd.DataFrame(np.matrix(all_y).T).to_csv('/home02/chenhuangrong/PseEIIP%d.csv'%select_num,header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[str(X_train.shape[1]),\"正：\"+str(pos_all)+'负：'+str(neg_all),'svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all]\n",
    "final_out_to_excel.append(savedata)\n",
    "\n",
    "print savedata\n",
    "pd.DataFrame(final_out_to_excel).to_excel('/home02/chenhuangrong/%d_gap_%d_gram.xlsx'%(gap,gram),sheet_name=\"independent_test\",index=False,header=False)\n",
    "#the process of save  data to disk end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16732, 64)\n",
      "             0         1         2         3         4         5         6   \\\n",
      "0      0.020738  0.018946  0.016137  0.018228  0.016256  0.013387  0.012013   \n",
      "1      0.020738  0.018945  0.016136  0.018228  0.016256  0.013387  0.012013   \n",
      "2      0.020738  0.018945  0.016136  0.018228  0.016256  0.013387  0.012012   \n",
      "3      0.020738  0.018945  0.016136  0.018228  0.016255  0.013387  0.012012   \n",
      "4      0.020737  0.018945  0.016136  0.018227  0.016255  0.013387  0.012012   \n",
      "5      0.020737  0.018944  0.016136  0.018227  0.016255  0.013387  0.012012   \n",
      "6      0.020737  0.018944  0.016135  0.018227  0.016255  0.013386  0.012012   \n",
      "7      0.020737  0.018944  0.016135  0.018227  0.016255  0.013386  0.012012   \n",
      "8      0.020736  0.018944  0.016135  0.018227  0.016255  0.013386  0.012012   \n",
      "9      0.020736  0.018943  0.016135  0.018226  0.016254  0.013386  0.012011   \n",
      "10     0.020736  0.018943  0.016135  0.018226  0.016254  0.013398  0.012011   \n",
      "11     0.020736  0.018943  0.016134  0.018226  0.016254  0.013398  0.012011   \n",
      "12     0.020735  0.018943  0.016134  0.018226  0.016254  0.013397  0.012011   \n",
      "13     0.020735  0.018943  0.016134  0.018225  0.016254  0.013397  0.012023   \n",
      "14     0.020735  0.018942  0.016134  0.018225  0.016253  0.013397  0.012023   \n",
      "15     0.020735  0.018942  0.016134  0.018225  0.016253  0.013397  0.012023   \n",
      "16     0.020734  0.018942  0.016133  0.018225  0.016253  0.013397  0.012022   \n",
      "17     0.020734  0.018942  0.016133  0.018225  0.016253  0.013397  0.012022   \n",
      "18     0.020734  0.018941  0.016133  0.018224  0.016253  0.013396  0.012022   \n",
      "19     0.020734  0.018941  0.016133  0.018224  0.016264  0.013396  0.012022   \n",
      "20     0.020733  0.018941  0.016133  0.018224  0.016264  0.013396  0.012022   \n",
      "21     0.020733  0.018941  0.016133  0.018224  0.016264  0.013396  0.012022   \n",
      "22     0.020733  0.018941  0.016132  0.018224  0.016264  0.013396  0.012022   \n",
      "23     0.020733  0.018940  0.016132  0.018223  0.016264  0.013396  0.012021   \n",
      "24     0.020733  0.018940  0.016132  0.018223  0.016263  0.013395  0.012021   \n",
      "25     0.020732  0.018940  0.016132  0.018223  0.016263  0.013395  0.012021   \n",
      "26     0.020732  0.018940  0.016132  0.018223  0.016263  0.013395  0.012021   \n",
      "27     0.020732  0.018939  0.016131  0.018222  0.016263  0.013395  0.012021   \n",
      "28     0.020732  0.018939  0.016131  0.018222  0.016263  0.013395  0.012033   \n",
      "29     0.020731  0.018939  0.016131  0.018222  0.016262  0.013395  0.012033   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "16702  0.020745  0.018941  0.016141  0.018204  0.016251  0.013391  0.012016   \n",
      "16703  0.020744  0.018941  0.016141  0.018204  0.016251  0.013391  0.012016   \n",
      "16704  0.020744  0.018941  0.016141  0.018214  0.016251  0.013391  0.012016   \n",
      "16705  0.020744  0.018941  0.016141  0.018213  0.016251  0.013391  0.012016   \n",
      "16706  0.020744  0.018940  0.016141  0.018213  0.016250  0.013391  0.012016   \n",
      "16707  0.020744  0.018940  0.016141  0.018213  0.016250  0.013391  0.012016   \n",
      "16708  0.020743  0.018940  0.016140  0.018213  0.016250  0.013391  0.012016   \n",
      "16709  0.020743  0.018940  0.016140  0.018213  0.016250  0.013390  0.012016   \n",
      "16710  0.020743  0.018940  0.016140  0.018212  0.016250  0.013390  0.012015   \n",
      "16711  0.020743  0.018940  0.016140  0.018212  0.016250  0.013390  0.012015   \n",
      "16712  0.020743  0.018939  0.016140  0.018212  0.016249  0.013390  0.012015   \n",
      "16713  0.020742  0.018939  0.016140  0.018212  0.016249  0.013390  0.012015   \n",
      "16714  0.020742  0.018939  0.016139  0.018212  0.016249  0.013390  0.012015   \n",
      "16715  0.020742  0.018939  0.016139  0.018212  0.016259  0.013390  0.012015   \n",
      "16716  0.020742  0.018939  0.016139  0.018211  0.016259  0.013390  0.012015   \n",
      "16717  0.020742  0.018938  0.016139  0.018211  0.016259  0.013389  0.012015   \n",
      "16718  0.020741  0.018938  0.016139  0.018211  0.016258  0.013389  0.012014   \n",
      "16719  0.020741  0.018938  0.016139  0.018211  0.016258  0.013389  0.012014   \n",
      "16720  0.020741  0.018948  0.016139  0.018211  0.016258  0.013389  0.012014   \n",
      "16721  0.020741  0.018948  0.016138  0.018210  0.016258  0.013389  0.012014   \n",
      "16722  0.020741  0.018947  0.016138  0.018210  0.016258  0.013389  0.012014   \n",
      "16723  0.020740  0.018947  0.016138  0.018210  0.016258  0.013389  0.012014   \n",
      "16724  0.020740  0.018947  0.016138  0.018210  0.016257  0.013388  0.012014   \n",
      "16725  0.020740  0.018947  0.016138  0.018210  0.016257  0.013388  0.012014   \n",
      "16726  0.020740  0.018947  0.016138  0.018219  0.016257  0.013388  0.012014   \n",
      "16727  0.020740  0.018946  0.016137  0.018219  0.016257  0.013388  0.012013   \n",
      "16728  0.020739  0.018946  0.016137  0.018219  0.016257  0.013388  0.012013   \n",
      "16729  0.020739  0.018946  0.016137  0.018229  0.016257  0.013388  0.012013   \n",
      "16730  0.020739  0.018946  0.016137  0.018229  0.016256  0.013388  0.012013   \n",
      "16731  0.020739  0.018946  0.016137  0.018229  0.016256  0.013388  0.012013   \n",
      "\n",
      "             7         8         9     ...           54        55        56  \\\n",
      "0      0.014344  0.016376  0.012610    ...     0.013387  0.014702  0.013925   \n",
      "1      0.014343  0.016375  0.012610    ...     0.013387  0.014702  0.013925   \n",
      "2      0.014343  0.016375  0.012610    ...     0.013387  0.014702  0.013925   \n",
      "3      0.014343  0.016375  0.012610    ...     0.013387  0.014702  0.013937   \n",
      "4      0.014343  0.016375  0.012610    ...     0.013387  0.014701  0.013937   \n",
      "5      0.014343  0.016375  0.012610    ...     0.013387  0.014701  0.013936   \n",
      "6      0.014343  0.016374  0.012610    ...     0.013386  0.014701  0.013936   \n",
      "7      0.014342  0.016374  0.012609    ...     0.013386  0.014701  0.013936   \n",
      "8      0.014342  0.016374  0.012609    ...     0.013386  0.014701  0.013936   \n",
      "9      0.014342  0.016374  0.012609    ...     0.013386  0.014701  0.013936   \n",
      "10     0.014342  0.016374  0.012609    ...     0.013386  0.014700  0.013936   \n",
      "11     0.014342  0.016373  0.012609    ...     0.013386  0.014700  0.013935   \n",
      "12     0.014342  0.016373  0.012609    ...     0.013385  0.014700  0.013935   \n",
      "13     0.014341  0.016373  0.012608    ...     0.013385  0.014700  0.013935   \n",
      "14     0.014341  0.016373  0.012608    ...     0.013385  0.014700  0.013947   \n",
      "15     0.014341  0.016373  0.012608    ...     0.013385  0.014700  0.013947   \n",
      "16     0.014341  0.016372  0.012608    ...     0.013385  0.014699  0.013946   \n",
      "17     0.014341  0.016372  0.012608    ...     0.013385  0.014699  0.013946   \n",
      "18     0.014341  0.016372  0.012608    ...     0.013384  0.014699  0.013946   \n",
      "19     0.014340  0.016372  0.012608    ...     0.013384  0.014699  0.013946   \n",
      "20     0.014340  0.016372  0.012607    ...     0.013384  0.014699  0.013946   \n",
      "21     0.014340  0.016372  0.012607    ...     0.013384  0.014699  0.013946   \n",
      "22     0.014340  0.016371  0.012607    ...     0.013384  0.014698  0.013945   \n",
      "23     0.014340  0.016371  0.012607    ...     0.013384  0.014698  0.013945   \n",
      "24     0.014339  0.016371  0.012607    ...     0.013384  0.014698  0.013945   \n",
      "25     0.014339  0.016371  0.012607    ...     0.013383  0.014698  0.013945   \n",
      "26     0.014339  0.016371  0.012606    ...     0.013383  0.014698  0.013945   \n",
      "27     0.014339  0.016370  0.012606    ...     0.013383  0.014697  0.013945   \n",
      "28     0.014339  0.016370  0.012606    ...     0.013383  0.014697  0.013944   \n",
      "29     0.014339  0.016370  0.012606    ...     0.013395  0.014697  0.013944   \n",
      "...         ...       ...       ...    ...          ...       ...       ...   \n",
      "16702  0.014348  0.016381  0.012614    ...     0.013391  0.014697  0.013929   \n",
      "16703  0.014348  0.016380  0.012614    ...     0.013391  0.014697  0.013929   \n",
      "16704  0.014348  0.016380  0.012614    ...     0.013391  0.014696  0.013929   \n",
      "16705  0.014347  0.016380  0.012614    ...     0.013391  0.014696  0.013929   \n",
      "16706  0.014347  0.016380  0.012614    ...     0.013391  0.014696  0.013929   \n",
      "16707  0.014347  0.016380  0.012614    ...     0.013391  0.014696  0.013929   \n",
      "16708  0.014347  0.016380  0.012613    ...     0.013391  0.014696  0.013929   \n",
      "16709  0.014347  0.016379  0.012613    ...     0.013390  0.014696  0.013928   \n",
      "16710  0.014347  0.016379  0.012613    ...     0.013390  0.014695  0.013928   \n",
      "16711  0.014347  0.016379  0.012613    ...     0.013390  0.014695  0.013928   \n",
      "16712  0.014346  0.016379  0.012613    ...     0.013390  0.014695  0.013928   \n",
      "16713  0.014346  0.016379  0.012613    ...     0.013390  0.014695  0.013928   \n",
      "16714  0.014346  0.016379  0.012613    ...     0.013390  0.014695  0.013928   \n",
      "16715  0.014346  0.016378  0.012613    ...     0.013390  0.014695  0.013928   \n",
      "16716  0.014346  0.016378  0.012612    ...     0.013390  0.014695  0.013927   \n",
      "16717  0.014346  0.016378  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16718  0.014346  0.016378  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16719  0.014345  0.016378  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16720  0.014345  0.016378  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16721  0.014345  0.016377  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16722  0.014345  0.016377  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16723  0.014345  0.016377  0.012612    ...     0.013389  0.014694  0.013927   \n",
      "16724  0.014345  0.016377  0.012611    ...     0.013388  0.014693  0.013926   \n",
      "16725  0.014345  0.016377  0.012611    ...     0.013388  0.014703  0.013926   \n",
      "16726  0.014344  0.016377  0.012611    ...     0.013388  0.014703  0.013926   \n",
      "16727  0.014344  0.016376  0.012611    ...     0.013388  0.014703  0.013926   \n",
      "16728  0.014344  0.016376  0.012611    ...     0.013388  0.014703  0.013926   \n",
      "16729  0.014344  0.016376  0.012611    ...     0.013388  0.014703  0.013926   \n",
      "16730  0.014344  0.016376  0.012611    ...     0.013388  0.014703  0.013926   \n",
      "16731  0.014344  0.016376  0.012611    ...     0.013388  0.014702  0.013925   \n",
      "\n",
      "             57        58        59        60        61        62        63  \n",
      "0      0.012431  0.018049  0.018946  0.023249  0.014822  0.019065  0.026595  \n",
      "1      0.012431  0.018049  0.018945  0.023248  0.014822  0.019065  0.026595  \n",
      "2      0.012431  0.018049  0.018945  0.023248  0.014821  0.019065  0.026595  \n",
      "3      0.012431  0.018048  0.018945  0.023248  0.014821  0.019064  0.026594  \n",
      "4      0.012431  0.018048  0.018945  0.023247  0.014821  0.019064  0.026594  \n",
      "5      0.012430  0.018048  0.018944  0.023247  0.014821  0.019064  0.026594  \n",
      "6      0.012430  0.018048  0.018944  0.023247  0.014821  0.019064  0.026594  \n",
      "7      0.012430  0.018048  0.018944  0.023247  0.014820  0.019063  0.026593  \n",
      "8      0.012430  0.018047  0.018944  0.023246  0.014820  0.019063  0.026593  \n",
      "9      0.012430  0.018047  0.018943  0.023246  0.014820  0.019063  0.026593  \n",
      "10     0.012430  0.018047  0.018943  0.023246  0.014820  0.019063  0.026592  \n",
      "11     0.012429  0.018047  0.018943  0.023246  0.014820  0.019063  0.026592  \n",
      "12     0.012429  0.018046  0.018943  0.023245  0.014820  0.019062  0.026592  \n",
      "13     0.012429  0.018046  0.018943  0.023245  0.014819  0.019062  0.026591  \n",
      "14     0.012429  0.018046  0.018942  0.023245  0.014819  0.019062  0.026591  \n",
      "15     0.012429  0.018046  0.018942  0.023244  0.014819  0.019062  0.026591  \n",
      "16     0.012429  0.018046  0.018942  0.023244  0.014819  0.019061  0.026590  \n",
      "17     0.012429  0.018045  0.018942  0.023244  0.014819  0.019061  0.026590  \n",
      "18     0.012428  0.018045  0.018941  0.023244  0.014819  0.019061  0.026590  \n",
      "19     0.012428  0.018045  0.018941  0.023243  0.014818  0.019061  0.026589  \n",
      "20     0.012428  0.018045  0.018941  0.023243  0.014818  0.019060  0.026589  \n",
      "21     0.012428  0.018045  0.018941  0.023243  0.014818  0.019060  0.026589  \n",
      "22     0.012428  0.018044  0.018941  0.023242  0.014818  0.019060  0.026588  \n",
      "23     0.012428  0.018044  0.018940  0.023242  0.014818  0.019060  0.026588  \n",
      "24     0.012428  0.018044  0.018940  0.023242  0.014817  0.019060  0.026588  \n",
      "25     0.012427  0.018044  0.018940  0.023242  0.014817  0.019059  0.026587  \n",
      "26     0.012427  0.018043  0.018940  0.023241  0.014817  0.019059  0.026587  \n",
      "27     0.012427  0.018043  0.018939  0.023241  0.014817  0.019059  0.026587  \n",
      "28     0.012427  0.018043  0.018939  0.023241  0.014817  0.019059  0.026587  \n",
      "29     0.012427  0.018043  0.018939  0.023241  0.014817  0.019058  0.026586  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "16702  0.012435  0.018054  0.018941  0.023256  0.014826  0.019071  0.026593  \n",
      "16703  0.012435  0.018054  0.018941  0.023255  0.014826  0.019071  0.026593  \n",
      "16704  0.012435  0.018054  0.018941  0.023255  0.014826  0.019070  0.026593  \n",
      "16705  0.012434  0.018054  0.018941  0.023255  0.014826  0.019070  0.026593  \n",
      "16706  0.012434  0.018054  0.018940  0.023255  0.014826  0.019070  0.026592  \n",
      "16707  0.012434  0.018054  0.018940  0.023254  0.014825  0.019070  0.026592  \n",
      "16708  0.012434  0.018053  0.018940  0.023254  0.014825  0.019070  0.026592  \n",
      "16709  0.012434  0.018053  0.018940  0.023254  0.014825  0.019069  0.026592  \n",
      "16710  0.012434  0.018053  0.018940  0.023254  0.014825  0.019069  0.026591  \n",
      "16711  0.012434  0.018053  0.018940  0.023253  0.014825  0.019069  0.026591  \n",
      "16712  0.012434  0.018053  0.018939  0.023253  0.014825  0.019069  0.026591  \n",
      "16713  0.012433  0.018052  0.018939  0.023253  0.014825  0.019069  0.026591  \n",
      "16714  0.012433  0.018052  0.018939  0.023253  0.014824  0.019068  0.026590  \n",
      "16715  0.012433  0.018052  0.018939  0.023253  0.014824  0.019068  0.026590  \n",
      "16716  0.012433  0.018052  0.018939  0.023252  0.014824  0.019068  0.026590  \n",
      "16717  0.012433  0.018052  0.018948  0.023252  0.014824  0.019068  0.026589  \n",
      "16718  0.012433  0.018052  0.018948  0.023252  0.014824  0.019068  0.026599  \n",
      "16719  0.012433  0.018051  0.018948  0.023252  0.014824  0.019068  0.026599  \n",
      "16720  0.012433  0.018051  0.018948  0.023251  0.014824  0.019067  0.026599  \n",
      "16721  0.012433  0.018051  0.018948  0.023251  0.014823  0.019067  0.026598  \n",
      "16722  0.012432  0.018051  0.018947  0.023251  0.014823  0.019067  0.026598  \n",
      "16723  0.012432  0.018051  0.018947  0.023251  0.014823  0.019067  0.026598  \n",
      "16724  0.012432  0.018051  0.018947  0.023250  0.014823  0.019067  0.026598  \n",
      "16725  0.012432  0.018050  0.018947  0.023250  0.014823  0.019066  0.026597  \n",
      "16726  0.012432  0.018050  0.018947  0.023250  0.014823  0.019066  0.026597  \n",
      "16727  0.012432  0.018050  0.018946  0.023250  0.014822  0.019066  0.026597  \n",
      "16728  0.012432  0.018050  0.018946  0.023250  0.014822  0.019066  0.026597  \n",
      "16729  0.012432  0.018050  0.018946  0.023249  0.014822  0.019066  0.026596  \n",
      "16730  0.012431  0.018049  0.018946  0.023249  0.014822  0.019065  0.026596  \n",
      "16731  0.012431  0.018049  0.018946  0.023249  0.014822  0.019065  0.026596  \n",
      "\n",
      "[16732 rows x 64 columns]\n",
      "16732\n",
      "0.5\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "used to test the final performance with other dataset\n",
    "\"\"\"\n",
    "\n",
    "m6a_benchmark_dataset='/home02/chenhuangrong/Homo_sapiens_used_test.fasta'\n",
    "matrix_data=read_fasta_file(m6a_benchmark_dataset)\n",
    "final_feature_matrix=AthMethPre_feature_extraction(matrix_data)\n",
    "print np.array(final_feature_matrix).shape\n",
    "final_feature_matrix=pd.DataFrame(final_feature_matrix)\n",
    "print final_feature_matrix\n",
    "Y_train = list(map(lambda x: 1, xrange(len(final_feature_matrix.values) / 2)))\n",
    "Y2_train = list(map(lambda x: 0, xrange(len(final_feature_matrix.values) / 2)))\n",
    "Y_train.extend(Y2_train)\n",
    "print len(Y_train)\n",
    "clf=joblib.load('/home02/chenhuangrong/%d_gap_%d_gram.csv'%(gap,gram))\n",
    "#getting predict probability and predict label begining\n",
    "y_pred=clf.predict(final_feature_matrix.values)\n",
    "#getting predict probability and predict label begining\n",
    "\n",
    "\n",
    "ACC=metrics.accuracy_score(Y_train,y_pred)\n",
    "print ACC\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_train, y_pred) \n",
    "F1_Score=metrics.f1_score(Y_train, y_pred)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y_train, y_pred)\n",
    "print MCC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
