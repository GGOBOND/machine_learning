{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "class F_score:\n",
    "    index=[]\n",
    "    dimension=1\n",
    "    def fit_transform(self,train_data,dimension=1):\n",
    "        train_positive_data=train_data[0:len(train_data)/2]\n",
    "        train_negative_data=train_data[len(train_data)/2:len(train_data)]\n",
    "        train_positive_len=len(train_positive_data)\n",
    "        train_negative_len=len(train_negative_data)\n",
    "        train_positive_vector=reduce(lambda x,y:np.array(x)+np.array(y),train_positive_data)\n",
    "        train_vector=reduce(lambda x,y:np.array(x)+np.array(y),train_data)\n",
    "        train_negative_vector=reduce(lambda x,y:np.array(x)+np.array(y),train_negative_data)\n",
    "        numerator=np.array([math.pow(e,2) for e in (train_positive_vector-train_vector)])+np.array([math.pow(e,2) for e in (train_negative_vector-train_vector)])\n",
    "        numerator=np.array(numerator)\n",
    "        positive_denominator=reduce(lambda x,y:x+y,np.array([map(lambda x:math.pow(x,2),(e-train_positive_vector)) for e in train_positive_data]))*(1.0/(train_positive_len-1))\n",
    "        negative_denominator=reduce(lambda x,y:x+y,np.array([map(lambda x:math.pow(x,2),(e-train_negative_vector)) for e in train_negative_data]))*(1.0/(train_negative_len-1))\n",
    "        denominator=positive_denominator+negative_denominator\n",
    "        F_score_values=numerator/denominator\n",
    "        F_score_values=pd.DataFrame(F_score_values).fillna(0)\n",
    "#         print F_score_values.sort(0, ascending=False)\n",
    "        F_score_values=F_score_values.sort_values(by=[0],ascending=False)\n",
    "        train_index=list(F_score_values.index)[0:dimension]\n",
    "        self.index=cp.deepcopy(train_index)\n",
    "        self.dimension=dimension\n",
    "        train_data_final=pd.DataFrame(train_data).iloc[:,train_index]\n",
    "        return np.array(train_data_final)\n",
    "    def __init__(self):\n",
    "        print \"F_score instance success\"\n",
    "    def transform(self,test_data):\n",
    "        test_data=pd.DataFrame(test_data)\n",
    "        test_data_final=test_data.iloc[:,self.index]\n",
    "        return np.array(test_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_score instance success\n",
      "PCA success\n",
      "150\n",
      "already get train and test data\n",
      "begin ten cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b93bed68048f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"begin ten cross validation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home02/chenhuangrong/RFH_PSNP%d.model'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnum_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding:utf-8\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "import sklearn\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall==0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "final_out_to_excel=[]\n",
    "row0 = [u'特征集', u'样本个数', u'分类器', u'Accuracy', u'Precision', u'Recall', u'SN', u'SP',\n",
    "                u'Gm', u'F_measure', u'F_score', u'MCC', u'ROC曲线面积', u'tp', u'fn', u'fp', u'tn']\n",
    "final_out_to_excel.append(row0)\n",
    "seq=[]\n",
    "m6a_2614_sequence=\"/home02/chenhuangrong/m6a_data.txt\"\n",
    "\n",
    "RFH_feature=pd.read_csv('/home02/chenhuangrong/position_specific.csv',header=None,index_col=False)\n",
    "RFH_feature=RFH_feature.values\n",
    "RFH_positive_feature=RFH_feature[:len(RFH_feature)/2]\n",
    "RFH_negative_feature=RFH_feature[len(RFH_feature)/2:]\n",
    "\n",
    "RNA_code='ACGU'\n",
    "k=1\n",
    "interval=1\n",
    "select_num=40\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "# X_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data, train_target, test_size=0.1, random_state=0)\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "for select_num in xrange(150,151):\n",
    "    y_pred_prob_all=[]\n",
    "    y_pred_all=[]\n",
    "    Y_all=[]\n",
    "    ACC_all=0\n",
    "    precision_all=0\n",
    "    recall_all=0\n",
    "    SN_all=0\n",
    "    SP_all=0\n",
    "    GM_all=0\n",
    "    TP_all=0\n",
    "    TN_all=0\n",
    "    FP_all=0\n",
    "    FN_all=0\n",
    "    F_measure_all=0\n",
    "    F1_Score_all=0\n",
    "    pos_all=0\n",
    "    neg_all=0\n",
    "    MCC_all=0\n",
    "    num_mark=0\n",
    "    for train_index , test_index in kf.split(positive_seq):  \n",
    "        num_mark=num_mark+1\n",
    "        positive_df=pd.DataFrame(positive_seq)\n",
    "        positive_x_train=positive_df.iloc[train_index,:]\n",
    "        positive_y_train=positive_df.iloc[test_index,:]\n",
    "        negative_df=pd.DataFrame(negative_seq)\n",
    "        negative_x_train=negative_df.iloc[train_index,:]\n",
    "        negative_y_train=negative_df.iloc[test_index,:]\n",
    "        positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "        positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "        \n",
    "        RFH_postive_train_x=pd.DataFrame(RFH_positive_feature).iloc[train_index,:]\n",
    "        RFH_postive_test_y=pd.DataFrame(RFH_positive_feature).iloc[test_index,:]\n",
    "        RFH_negative_train_x=pd.DataFrame(RFH_negative_feature).iloc[train_index,:]\n",
    "        RFH_negative_test_y=pd.DataFrame(RFH_negative_feature).iloc[test_index,:]\n",
    "        RFH_train_x=np.concatenate([RFH_postive_train_x,RFH_negative_train_x])\n",
    "        RFH_test_y=np.concatenate([RFH_postive_test_y,RFH_negative_test_y])\n",
    "        final_seq_value=[[0 for ii in xrange(len(seq[0])-interval)] for jj in xrange(len(positive_negative_x_train))]\n",
    "        code_values=make_kmer_list(interval,RNA_code)\n",
    "        code_len=len(code_values)\n",
    "        positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval)] for ii in xrange(code_len)]\n",
    "        negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval)] for ii in xrange(code_len)]\n",
    "        for i,line_value in enumerate(positive_x_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                            positive_seq_value[p][j]+=1\n",
    "        positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "        pd.DataFrame(positive_seq_value).to_csv('/home02/chenhuangrong/positive_seq_value_%d'%num_mark,index=False,header=None)\n",
    "        for i,line_value in enumerate(negative_x_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                            negative_seq_value[p][j]+=1\n",
    "        negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "        pd.DataFrame(negative_seq_value).to_csv('/home02/chenhuangrong/negative_seq_value_%d'%num_mark,index=False,header=None)\n",
    "        for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                              final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "        y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval)] for jj in xrange(len(positive_negative_y_train))]\n",
    "        \n",
    "\n",
    "        for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                              y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "        \n",
    "        f=F_score()\n",
    "        X_train=pd.DataFrame(final_seq_value)\n",
    "        RFH_train_x=pd.DataFrame(RFH_train_x)\n",
    "        X_train_=pd.concat([X_train,RFH_train_x],axis=1)\n",
    "        scaler=sklearn.preprocessing.MinMaxScaler()\n",
    "        X_train_=pd.DataFrame(X_train_)\n",
    "        X_train_=scaler.fit_transform(X_train_)\n",
    "        X_train_=np.array(X_train_)\n",
    "        X_train_=f.fit_transform(X_train_,select_num)\n",
    "        X_train=np.array(X_train_)\n",
    "        Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "        Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "        Y_train.extend(Y2_train)\n",
    "        Y_train = np.array(Y_train)\n",
    "\n",
    "        X_test=pd.DataFrame(y_final_seq_value)\n",
    "        RFH_test_y=pd.DataFrame(RFH_test_y)\n",
    "        X_test_=pd.concat([X_test,RFH_test_y],axis=1)\n",
    "        X_test_=pd.DataFrame(X_test_)\n",
    "        X_test_=scaler.transform(X_test_)\n",
    "        X_test_=np.array(X_test_)\n",
    "        X_test_=f.transform(X_test_)\n",
    "        X_test=np.array(X_test_)\n",
    "        Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "        Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "        Y_test.extend(Y2_test )\n",
    "        Y_test  = np.array(Y_test)\n",
    "        print \"PCA success\"\n",
    "        print select_num\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        print \"already get train and test data\"\n",
    "        svc = svm.SVC(probability=True)\n",
    "        parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,28)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,28))}\n",
    "        print \"begin ten cross validation\"\n",
    "        clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        joblib.dump(clf, '/home02/chenhuangrong/RFH_PSNP%d.model'%num_mark)\n",
    "        C=clf.best_params_['C']\n",
    "        y_pred_prob=clf.predict_proba(X_test)\n",
    "\n",
    "        gamma=clf.best_params_['gamma']\n",
    "        print 'c:',C,'gamma:',gamma\n",
    "        y_pred=clf.predict(X_test)\n",
    "\n",
    "        y_pred_prob_all.extend(y_pred_prob)\n",
    "        y_pred_all.extend(y_pred)\n",
    "        Y_all.extend(Y_test)\n",
    "        ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "        print ACC\n",
    "        precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "        F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "        F_measure=F1_Score\n",
    "        MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "\n",
    "        pos=TP+FN\n",
    "        neg=FP+TN\n",
    "        ACC_all=ACC_all+ACC\n",
    "        print \"ACC_all:\",ACC_all\n",
    "        precision_all=precision_all+precision\n",
    "        recall_all=recall_all+recall\n",
    "        SN_all=SN_all+SN\n",
    "        SP_all=SP_all+SP\n",
    "        GM_all=GM_all+GM\n",
    "        TP_all=TP_all+TP\n",
    "        TN_all=TN_all+TN\n",
    "        FP_all=FP_all+FP\n",
    "        FN_all=FN_all+FN\n",
    "        F_measure_all=F_measure_all+F_measure\n",
    "        F1_Score_all=F1_Score_all+F1_Score\n",
    "        pos_all=pos_all+pos\n",
    "        neg_all=neg_all+neg\n",
    "        MCC_all=MCC_all+MCC\n",
    "    all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "    pd.DataFrame(np.matrix(all_y).T).to_csv('/home02/chenhuangrong/PsCPm6APred_independent_test_with_F_Score%d.csv'%select_num,header=None,index=False)\n",
    "    fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "   \n",
    "    savedata=[str(X_train.shape[1])+\"select_num:\"+str(select_num),\"正\"+str(pos_all)+'负'+str(neg_all),'svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "                SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "                FN_all,FP_all,TN_all]\n",
    "    final_out_to_excel.append(savedata)\n",
    "print savedata\n",
    "pd.DataFrame(final_out_to_excel).to_excel(\"/home02/chenhuangrong/PsCPm6APred_PSNP_F_score.xlsx\",sheet_name=\"F_score\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.895314734562\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "data=pd.read_csv('/home01/chenhuangrong/ROC/position_specific_global_occurence_frequency_independent_test_1.csv',header=None,index_col=None)\n",
    "data=data.values\n",
    "Y=data[:,0]\n",
    "Y_pred_label=data[:,2]\n",
    "fpr, tpr, thresholds = roc_curve(Y,Y_pred_label)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.54494529,  0.45505471],\n",
       "        [ 0.5       ,  0.5       ],\n",
       "        [ 0.66723297,  0.33276703],\n",
       "        [ 0.81103538,  0.18896462],\n",
       "        [ 0.64618439,  0.35381561],\n",
       "        [ 0.60410613,  0.39589387],\n",
       "        [ 0.4880726 ,  0.5119274 ],\n",
       "        [ 0.6004433 ,  0.3995567 ],\n",
       "        [ 0.5730875 ,  0.4269125 ],\n",
       "        [ 0.86230927,  0.13769073],\n",
       "        [ 0.60951654,  0.39048346],\n",
       "        [ 0.57258368,  0.42741632],\n",
       "        [ 0.48731522,  0.51268478],\n",
       "        [ 0.74680063,  0.25319937],\n",
       "        [ 0.6698448 ,  0.3301552 ],\n",
       "        [ 0.5       ,  0.5       ],\n",
       "        [ 0.68147176,  0.31852824],\n",
       "        [ 0.49252161,  0.50747839],\n",
       "        [ 0.59183687,  0.40816313],\n",
       "        [ 0.51440312,  0.48559688],\n",
       "        [ 0.48474693,  0.51525307],\n",
       "        [ 0.60490452,  0.39509548],\n",
       "        [ 0.67191245,  0.32808755],\n",
       "        [ 0.51281082,  0.48718918],\n",
       "        [ 0.41557756,  0.58442244],\n",
       "        [ 0.52343955,  0.47656045],\n",
       "        [ 0.67726   ,  0.32274   ],\n",
       "        [ 0.55144718,  0.44855282],\n",
       "        [ 0.51651148,  0.48348852],\n",
       "        [ 0.74909603,  0.25090397],\n",
       "        [ 0.54980446,  0.45019554],\n",
       "        [ 0.51846676,  0.48153324],\n",
       "        [ 0.55874272,  0.44125728],\n",
       "        [ 0.66902945,  0.33097055],\n",
       "        [ 0.8171778 ,  0.1828222 ],\n",
       "        [ 0.7285155 ,  0.2714845 ],\n",
       "        [ 0.6067677 ,  0.3932323 ],\n",
       "        [ 0.57240669,  0.42759331],\n",
       "        [ 0.53744183,  0.46255817],\n",
       "        [ 0.53236019,  0.46763981],\n",
       "        [ 0.59805479,  0.40194521],\n",
       "        [ 0.51909486,  0.48090514],\n",
       "        [ 0.55053817,  0.44946183],\n",
       "        [ 0.59210236,  0.40789764],\n",
       "        [ 0.5347569 ,  0.4652431 ],\n",
       "        [ 0.580858  ,  0.419142  ],\n",
       "        [ 0.59230685,  0.40769315],\n",
       "        [ 0.52788497,  0.47211503],\n",
       "        [ 0.52754639,  0.47245361],\n",
       "        [ 0.4906335 ,  0.5093665 ],\n",
       "        [ 0.56807826,  0.43192174],\n",
       "        [ 0.46459125,  0.53540875],\n",
       "        [ 0.60948581,  0.39051419],\n",
       "        [ 0.60001392,  0.39998608],\n",
       "        [ 0.4687874 ,  0.5312126 ],\n",
       "        [ 0.52866511,  0.47133489],\n",
       "        [ 0.57710583,  0.42289417],\n",
       "        [ 0.59657282,  0.40342718],\n",
       "        [ 0.51258171,  0.48741829],\n",
       "        [ 0.66292317,  0.33707683],\n",
       "        [ 0.60501391,  0.39498609],\n",
       "        [ 0.74657841,  0.25342159],\n",
       "        [ 0.63369897,  0.36630103],\n",
       "        [ 0.55298723,  0.44701277],\n",
       "        [ 0.57345564,  0.42654436],\n",
       "        [ 0.53830226,  0.46169774],\n",
       "        [ 0.59132331,  0.40867669],\n",
       "        [ 0.6511356 ,  0.3488644 ],\n",
       "        [ 0.65094276,  0.34905724],\n",
       "        [ 0.70145084,  0.29854916],\n",
       "        [ 0.50747506,  0.49252494],\n",
       "        [ 0.79909374,  0.20090626],\n",
       "        [ 0.47926295,  0.52073705],\n",
       "        [ 0.71403471,  0.28596529],\n",
       "        [ 0.73654476,  0.26345524],\n",
       "        [ 0.58559611,  0.41440389],\n",
       "        [ 0.76941534,  0.23058466],\n",
       "        [ 0.51524191,  0.48475809],\n",
       "        [ 0.58397819,  0.41602181],\n",
       "        [ 0.71792611,  0.28207389],\n",
       "        [ 0.58242117,  0.41757883],\n",
       "        [ 0.69983578,  0.30016422],\n",
       "        [ 0.60713416,  0.39286584],\n",
       "        [ 0.5992902 ,  0.4007098 ],\n",
       "        [ 0.65323002,  0.34676998],\n",
       "        [ 0.54139468,  0.45860532],\n",
       "        [ 0.75387426,  0.24612574],\n",
       "        [ 0.57476056,  0.42523944],\n",
       "        [ 0.48379641,  0.51620359],\n",
       "        [ 0.55948098,  0.44051902],\n",
       "        [ 0.57772929,  0.42227071],\n",
       "        [ 0.59243746,  0.40756254],\n",
       "        [ 0.5502689 ,  0.4497311 ],\n",
       "        [ 0.59028028,  0.40971972],\n",
       "        [ 0.45363761,  0.54636239],\n",
       "        [ 0.60561861,  0.39438139],\n",
       "        [ 0.47826991,  0.52173009],\n",
       "        [ 0.51932078,  0.48067922],\n",
       "        [ 0.5610592 ,  0.4389408 ],\n",
       "        [ 0.48813381,  0.51186619],\n",
       "        [ 0.55228065,  0.44771935],\n",
       "        [ 0.73074008,  0.26925992],\n",
       "        [ 0.5       ,  0.5       ],\n",
       "        [ 0.5896293 ,  0.4103707 ],\n",
       "        [ 0.5196666 ,  0.4803334 ],\n",
       "        [ 0.47377688,  0.52622312],\n",
       "        [ 0.54689838,  0.45310162],\n",
       "        [ 0.47319833,  0.52680167],\n",
       "        [ 0.44529896,  0.55470104],\n",
       "        [ 0.59631098,  0.40368902],\n",
       "        [ 0.70714628,  0.29285372],\n",
       "        [ 0.68599914,  0.31400086],\n",
       "        [ 0.80786782,  0.19213218],\n",
       "        [ 0.62817418,  0.37182582],\n",
       "        [ 0.52612633,  0.47387367],\n",
       "        [ 0.77148352,  0.22851648],\n",
       "        [ 0.79224492,  0.20775508],\n",
       "        [ 0.60593797,  0.39406203],\n",
       "        [ 0.60557067,  0.39442933],\n",
       "        [ 0.58001488,  0.41998512],\n",
       "        [ 0.43649675,  0.56350325],\n",
       "        [ 0.55382103,  0.44617897],\n",
       "        [ 0.60320861,  0.39679139],\n",
       "        [ 0.76190804,  0.23809196],\n",
       "        [ 0.47796831,  0.52203169],\n",
       "        [ 0.54658981,  0.45341019],\n",
       "        [ 0.60241453,  0.39758547],\n",
       "        [ 0.53317698,  0.46682302],\n",
       "        [ 0.64378416,  0.35621584],\n",
       "        [ 0.80696647,  0.19303353],\n",
       "        [ 0.37309375,  0.62690625],\n",
       "        [ 0.41105064,  0.58894936],\n",
       "        [ 0.37261363,  0.62738637],\n",
       "        [ 0.37801565,  0.62198435],\n",
       "        [ 0.27152024,  0.72847976],\n",
       "        [ 0.36015097,  0.63984903],\n",
       "        [ 0.41548583,  0.58451417],\n",
       "        [ 0.42361167,  0.57638833],\n",
       "        [ 0.37820548,  0.62179452],\n",
       "        [ 0.48054379,  0.51945621],\n",
       "        [ 0.40525795,  0.59474205],\n",
       "        [ 0.35788691,  0.64211309],\n",
       "        [ 0.34664324,  0.65335676],\n",
       "        [ 0.36344996,  0.63655004],\n",
       "        [ 0.61424589,  0.38575411],\n",
       "        [ 0.5       ,  0.5       ],\n",
       "        [ 0.39181761,  0.60818239],\n",
       "        [ 0.38870627,  0.61129373],\n",
       "        [ 0.32249979,  0.67750021],\n",
       "        [ 0.33568051,  0.66431949],\n",
       "        [ 0.41925616,  0.58074384],\n",
       "        [ 0.5303836 ,  0.4696164 ],\n",
       "        [ 0.34301632,  0.65698368],\n",
       "        [ 0.37413215,  0.62586785],\n",
       "        [ 0.39675919,  0.60324081],\n",
       "        [ 0.38404161,  0.61595839],\n",
       "        [ 0.32731192,  0.67268808],\n",
       "        [ 0.39634347,  0.60365653],\n",
       "        [ 0.36036113,  0.63963887],\n",
       "        [ 0.42216185,  0.57783815],\n",
       "        [ 0.35129512,  0.64870488],\n",
       "        [ 0.48502464,  0.51497536],\n",
       "        [ 0.30187016,  0.69812984],\n",
       "        [ 0.34771697,  0.65228303],\n",
       "        [ 0.49085767,  0.50914233],\n",
       "        [ 0.34547657,  0.65452343],\n",
       "        [ 0.30584519,  0.69415481],\n",
       "        [ 0.44888169,  0.55111831],\n",
       "        [ 0.42918192,  0.57081808],\n",
       "        [ 0.43316962,  0.56683038],\n",
       "        [ 0.44991294,  0.55008706],\n",
       "        [ 0.37584152,  0.62415848],\n",
       "        [ 0.42030467,  0.57969533],\n",
       "        [ 0.41145947,  0.58854053],\n",
       "        [ 0.32994409,  0.67005591],\n",
       "        [ 0.41246012,  0.58753988],\n",
       "        [ 0.29091423,  0.70908577],\n",
       "        [ 0.42092094,  0.57907906],\n",
       "        [ 0.39304054,  0.60695946],\n",
       "        [ 0.33847719,  0.66152281],\n",
       "        [ 0.51709577,  0.48290423],\n",
       "        [ 0.40583514,  0.59416486],\n",
       "        [ 0.37421259,  0.62578741],\n",
       "        [ 0.37867903,  0.62132097],\n",
       "        [ 0.50631671,  0.49368329],\n",
       "        [ 0.36203037,  0.63796963],\n",
       "        [ 0.47673079,  0.52326921],\n",
       "        [ 0.38748824,  0.61251176],\n",
       "        [ 0.4176827 ,  0.5823173 ],\n",
       "        [ 0.53435798,  0.46564202],\n",
       "        [ 0.39235496,  0.60764504],\n",
       "        [ 0.43514602,  0.56485398],\n",
       "        [ 0.42977295,  0.57022705],\n",
       "        [ 0.39737862,  0.60262138],\n",
       "        [ 0.41865528,  0.58134472],\n",
       "        [ 0.45419334,  0.54580666],\n",
       "        [ 0.27258223,  0.72741777],\n",
       "        [ 0.37291849,  0.62708151],\n",
       "        [ 0.39866459,  0.60133541],\n",
       "        [ 0.32957019,  0.67042981],\n",
       "        [ 0.46075696,  0.53924304],\n",
       "        [ 0.32844047,  0.67155953],\n",
       "        [ 0.37140916,  0.62859084],\n",
       "        [ 0.400679  ,  0.599321  ],\n",
       "        [ 0.46859461,  0.53140539],\n",
       "        [ 0.43689666,  0.56310334],\n",
       "        [ 0.44108016,  0.55891984],\n",
       "        [ 0.31765002,  0.68234998],\n",
       "        [ 0.46750395,  0.53249605],\n",
       "        [ 0.27029706,  0.72970294],\n",
       "        [ 0.5       ,  0.5       ],\n",
       "        [ 0.46587232,  0.53412768],\n",
       "        [ 0.39218562,  0.60781438],\n",
       "        [ 0.47915769,  0.52084231],\n",
       "        [ 0.3479647 ,  0.6520353 ],\n",
       "        [ 0.36913925,  0.63086075],\n",
       "        [ 0.5113027 ,  0.4886973 ],\n",
       "        [ 0.46057604,  0.53942396],\n",
       "        [ 0.43920343,  0.56079657],\n",
       "        [ 0.39404588,  0.60595412],\n",
       "        [ 0.39099748,  0.60900252],\n",
       "        [ 0.30602098,  0.69397902],\n",
       "        [ 0.44472984,  0.55527016],\n",
       "        [ 0.43194957,  0.56805043],\n",
       "        [ 0.46008821,  0.53991179],\n",
       "        [ 0.37659003,  0.62340997],\n",
       "        [ 0.32697173,  0.67302827],\n",
       "        [ 0.41765153,  0.58234847],\n",
       "        [ 0.34512684,  0.65487316],\n",
       "        [ 0.46458164,  0.53541836],\n",
       "        [ 0.31209301,  0.68790699],\n",
       "        [ 0.4089855 ,  0.5910145 ],\n",
       "        [ 0.41901535,  0.58098465],\n",
       "        [ 0.40878934,  0.59121066],\n",
       "        [ 0.39597023,  0.60402977],\n",
       "        [ 0.39069861,  0.60930139],\n",
       "        [ 0.33632497,  0.66367503],\n",
       "        [ 0.42696002,  0.57303998],\n",
       "        [ 0.35673757,  0.64326243],\n",
       "        [ 0.35171637,  0.64828363],\n",
       "        [ 0.33642909,  0.66357091],\n",
       "        [ 0.31658608,  0.68341392],\n",
       "        [ 0.24732357,  0.75267643],\n",
       "        [ 0.44550126,  0.55449874],\n",
       "        [ 0.34298406,  0.65701594],\n",
       "        [ 0.40953389,  0.59046611],\n",
       "        [ 0.51675287,  0.48324713],\n",
       "        [ 0.50950467,  0.49049533],\n",
       "        [ 0.39168416,  0.60831584],\n",
       "        [ 0.37046422,  0.62953578],\n",
       "        [ 0.43911476,  0.56088524],\n",
       "        [ 0.36917291,  0.63082709],\n",
       "        [ 0.34081516,  0.65918484],\n",
       "        [ 0.38004759,  0.61995241],\n",
       "        [ 0.41671818,  0.58328182],\n",
       "        [ 0.4355524 ,  0.5644476 ],\n",
       "        [ 0.37153078,  0.62846922],\n",
       "        [ 0.42653463,  0.57346537],\n",
       "        [ 0.37332349,  0.62667651],\n",
       "        [ 0.44807181,  0.55192819]]),\n",
       " array([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob,y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
