{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "path=\"data/\"\n",
    "inputname=\"human.fasta\"\n",
    "outputname=\"human_2_mer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(path):\n",
    "    '''\n",
    "    used for load fasta data and transformd into numpy.array format\n",
    "    '''\n",
    "    fh=open(path)\n",
    "    seq=[]\n",
    "    for line in fh:\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line.replace('\\r','').replace('\\n',''))\n",
    "    fh.close()\n",
    "    matrix_data=np.array([list(e) for e in seq])\n",
    "    return matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fetch_singleline_features(sequence):\n",
    "    alphabet=\"AUGC\"\n",
    "    k_num=2\n",
    "    single_line_feature=[0 for x in range(int(pow(4,k_num)))]\n",
    "    matrix=[\"\".join(e) for e in itertools.product(alphabet, repeat=k_num)] # AA AU AC AG UU UC ...\n",
    "    for index,character in enumerate(sequence):\n",
    "        if index <=len(sequence)-k_num and \"\".join(sequence[index:index+k_num]) in matrix:\n",
    "            single_line_feature[matrix.index(\"\".join(sequence[index:index+k_num]))]+=1\n",
    "    single_line_feature=np.array(single_line_feature)*1.0/(len(sequence)-k_num+1)\n",
    "    return single_line_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences-length:2260\n",
      "single-line-sequence-length:41\n",
      "features shape :(2260, 16)\n"
     ]
    }
   ],
   "source": [
    "sequences=read_fasta_file(path+inputname)\n",
    "print \"sequences-length:{}\".format(len(sequences))\n",
    "print \"single-line-sequence-length:{}\".format(len(sequences[0]))\n",
    "features_data=[]\n",
    "for index,sequence in enumerate(sequences):\n",
    "    features_data.append(fetch_singleline_features(sequence))\n",
    "print \"features shape :{}\".format(np.array(features_data).shape)\n",
    "pd.DataFrame(features_data).to_csv(path+outputname+\".csv\",header=None,index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['SVMC:2.82842712475gamma:4.0', 0.67079646017699113, 0.7075268817204301, 0.5823008849557522, 0.5823008849557522, 0.7592920353982301, 0.6649333982830489, 0.63883495145631064, 0.63883495145631064, 0.34707234483245386, 0.67079646017699113, 658.0, 472.0, 272.0, 858.0, 1130.0, 1130.0]]]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"SVM\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "svc = svm.SVC()\n",
    "parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "C=clf.best_params_['C']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "gamma=clf.best_params_['gamma']\n",
    "y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['GBDTn_estimators:14max_depth:7min_samples_split:300min_samples_leaf:60', 0.67079646017699113, 0.6922310756972112, 0.6150442477876106, 0.6150442477876106, 0.7265486725663717, 0.6684755655965826, 0.65135895032802249, 0.65135895032802249, 0.34373648258106537, 0.67079646017699113, 695.0, 435.0, 309.0, 821.0, 1130.0, 1130.0]]]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation GBDT\n",
    "\"\"\"\n",
    "classifier=\"GBDT\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "GBDT = GradientBoostingClassifier(learning_rate=0.1,min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "clf = GridSearchCV(GBDT, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_estimators=clf.best_params_['n_estimators']\n",
    "max_depth=clf.best_params_['max_depth']\n",
    "min_samples_split=clf.best_params_['min_samples_split']\n",
    "min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(GradientBoostingClassifier(n_estimators=n_estimators,learning_rate=0.1,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(GradientBoostingClassifier(n_estimators=n_estimators,learning_rate=0.1,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf),ACC,precision, recall,SN, SP,\n",
    "            GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cross validation RF\n",
    "\"\"\"\n",
    "classifier=\"RF\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "RF = RandomForestClassifier(min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "clf = GridSearchCV(RF, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_estimators=clf.best_params_['n_estimators']\n",
    "max_depth=clf.best_params_['max_depth']\n",
    "min_samples_split=clf.best_params_['min_samples_split']\n",
    "min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(RandomForestClassifier(n_estimators=n_estimators,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(RandomForestClassifier(n_estimators=n_estimators,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf),ACC,precision, recall,SN, SP,\n",
    "            GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cross validation NB\n",
    "\"\"\"\n",
    "classifier=\"NB\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(GaussianNB(),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(GaussianNB(),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier,ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"LR\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "logisReg = LogisticRegression()\n",
    "C_range = 10.0 ** np.arange(-4,3,1)\n",
    "grid_parame = dict(C=C_range)\n",
    "clf = GridSearchCV(logisReg, grid_parame, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "C=clf.best_params_['C']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "\n",
    "y_predict=cross_val_predict(LogisticRegression(C=C),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(LogisticRegression(C=C),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"C:\"+str(C),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"KNN\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "knn = KNeighborsClassifier()\n",
    "#设置k的范围\n",
    "k_range = list(range(1,10))\n",
    "leaf_range = list(range(1,2))\n",
    "weight_options = ['uniform','distance']\n",
    "algorithm_options = ['auto','ball_tree','kd_tree','brute']\n",
    "param_gridknn = dict(n_neighbors = k_range,weights = weight_options,algorithm=algorithm_options,leaf_size=leaf_range)\n",
    "clf = GridSearchCV(knn, param_gridknn, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_neighbors=clf.best_params_['n_neighbors']\n",
    "weights=clf.best_params_['weights']\n",
    "algorithm=clf.best_params_['algorithm']\n",
    "leaf_size=clf.best_params_['leaf_size']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "\n",
    "y_predict=cross_val_predict(KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,algorithm=algorithm,leaf_size=leaf_size),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,algorithm=algorithm,leaf_size=leaf_size),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_neighbors:\"+str(n_neighbors)+\"weights:\"+str(weights)+\"algorithm:\"+str(algorithm)+\"leaf_size:\"+str(leaf_size),\n",
    "            ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a468306d5568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                       }]\n\u001b[1;32m     17\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation RF\n",
    "\"\"\"\n",
    "classifier=\"XGBoost\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "parameters = [{'n_estimators':range(1,10,1),\n",
    "                      'max_depth':range(2,10),\n",
    "                      'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "                      'subsample':[0.75,0.8,0.85,0.9]\n",
    "                      }]\n",
    "clf = GridSearchCV(XGBClassifier(), parameters, cv=10, n_jobs=1, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_estimators=clf.best_params_['n_estimators']\n",
    "max_depth=clf.best_params_['max_depth']\n",
    "learning_rate=clf.best_params_['learning_rate']\n",
    "subsample=clf.best_params_['subsample']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,\n",
    "                                                       subsample=subsample,max_depth=max_depth),X,Y,cv=10,n_jobs=1)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,\n",
    "                                                       subsample=subsample,max_depth=max_depth),X,Y,cv=10,n_jobs=1,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"learning_rate:\"+str(learning_rate)+\"subsample:\"+str(subsample),ACC,precision, recall,SN, SP,\n",
    "            GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
