{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_selection import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_AthMethPre_XGBoost_predict.csv 0\n",
      "human_RFH_GBDT_predict.csv 1\n",
      "human_RFH_NB_predict.csv 2\n",
      "human_2RFH_XGBoost_predict.csv 3\n",
      "human_PSNP_SVM_predict.csv 4\n",
      "human_2RFH_NB_predict.csv 5\n",
      "6\n",
      "1\n",
      "[5]\n",
      "0.91017699115\n",
      "[[['svmC:0.25gamma:0.03125', 0.91017699115044248, 1.0, 0.820353982300885, 0.820353982300885, 1.0, 0.9057339467530655, 0.90131259115216333, 0.90131259115216333, 0.8339207731937075, '0.9102', 927.0, 203.0, 0.0, 1130.0, 1130.0, 1130.0]]]\n",
      "2\n",
      "[5 2]\n",
      "0.91017699115\n",
      "[[['svmC:0.25gamma:0.03125', 0.91017699115044248, 1.0, 0.820353982300885, 0.820353982300885, 1.0, 0.9057339467530655, 0.90131259115216333, 0.90131259115216333, 0.8339207731937075, '0.9102', 927.0, 203.0, 0.0, 1130.0, 1130.0, 1130.0]]]\n",
      "3\n",
      "[5 2 3]\n",
      "0.910619469027\n",
      "[[['svmC:0.25gamma:4.0', 0.91061946902654867, 0.9989247311827957, 0.8221238938053097, 0.8221238938053097, 0.9991150442477876, 0.9063091914663867, 0.90194174757281542, 0.90194174757281542, 0.8344122694417544, '0.9106', 929.0, 201.0, 1.0, 1129.0, 1130.0, 1130.0]]]\n",
      "4\n",
      "[5 2 3 4]\n",
      "0.910619469027\n",
      "[[['svmC:0.25gamma:1.78179743628', 0.91061946902654867, 0.9989247311827957, 0.8221238938053097, 0.8221238938053097, 0.9991150442477876, 0.9063091914663867, 0.90194174757281542, 0.90194174757281542, 0.8344122694417544, '0.9106', 929.0, 201.0, 1.0, 1129.0, 1130.0, 1130.0]]]\n",
      "5\n",
      "[5 2 3 4 1]\n",
      "0.910619469027\n",
      "[[['svmC:0.25gamma:1.78179743628', 0.91061946902654867, 0.9989247311827957, 0.8221238938053097, 0.8221238938053097, 0.9991150442477876, 0.9063091914663867, 0.90194174757281542, 0.90194174757281542, 0.8344122694417544, '0.9106', 929.0, 201.0, 1.0, 1129.0, 1130.0, 1130.0]]]\n",
      "6\n",
      "[5 2 3 4 1 0]\n",
      "0.911061946903\n",
      "[[['svmC:0.25gamma:1.78179743628', 0.91106194690265485, 0.9967914438502674, 0.8247787610619469, 0.8247787610619469, 0.9973451327433628, 0.9069669690431034, 0.90266343825665862, 0.90266343825665862, 0.83464533318448442, '0.9111', 932.0, 198.0, 3.0, 1127.0, 1130.0, 1130.0]]]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def generating_integrated_training(file_dir,samples_size):   \n",
    "    Y=[1 for e in xrange(samples_size)]\n",
    "    Y2=[0 for e in xrange(samples_size)]\n",
    "    Y.extend(Y2)\n",
    "    X=[]\n",
    "    for root, dirs, files in os.walk(file_dir):  \n",
    "#         print(root) #当前目录路径  \n",
    "#         print(dirs) #当前路径下所有子目录  \n",
    "        i=0\n",
    "        for e in files:\n",
    "                \n",
    "#             if re.search('predict.csv',e)!= None and re.search('human',e)!=None:\n",
    "            if re.search('human_AthMethPre_XGBoost_predict.csv',e)!= None or re.search('human_RFH_GBDT_predict.csv',e)!=None  \\\n",
    "            or re.search('human_PSNP_SVM_predict.csv',e)!=None or re.search('human_RFH_NB_predict.csv',e)!=None or re.search('human_2RFH_NB_predict.csv',e)!=None  \\\n",
    "             or re.search('human_2RFH_XGBoost_predict.csv',e)!=None:\n",
    "                print e,i\n",
    "                i=i+1\n",
    "                data=pd.read_csv(root+'/'+e,header=None,index_col=False)\n",
    "                data=data.values\n",
    "                positive_=[e for index,e in enumerate(data) if data[index,0] == 1 ]\n",
    "                negative_=[e for index,e in enumerate(data) if data[index,0] == 0 ]\n",
    "                positive_.extend(negative_)\n",
    "                data=np.array(positive_)\n",
    "                data=data[:,1]#设置为probability:2或者predict_label:1\n",
    "                X.append(data)\n",
    "    print len(X)\n",
    "    X=np.array(X).T\n",
    "    return X,Y\n",
    "if __name__ == '__main__':\n",
    "    X_,Y=generating_integrated_training('data/',1130)\n",
    "    for select_num in xrange(1,X_.shape[1]+1):\n",
    "        F,pval=f_classif(X_,Y)\n",
    "        idx=np.argsort(F)[::-1]\n",
    "        select_list=idx[xrange(select_num)]\n",
    "        X=pd.DataFrame(X_).iloc[:,select_list]\n",
    "        X=X.values\n",
    "\n",
    "    #     pd.DataFrame(X).to_csv('/home02/chenhuangrong/integrated_training_files2.csv',header=None,index=False)\n",
    "        print select_num\n",
    "        print select_list\n",
    "        svc = svm.SVC()\n",
    "        parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    #     parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-5,15,30)), 'gamma':map(lambda x:2**x,np.linspace(-15,5,30))}\n",
    "        clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "        clf.fit(X, Y)\n",
    "        C=clf.best_params_['C']\n",
    "        # joblib.dump(clf,'/home02/chenhuangrong/%d_gap_%d_gram.csv'%(gap,gram))\n",
    "        print clf.best_score_\n",
    "        gamma=clf.best_params_['gamma']\n",
    "        y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,),X,Y,cv=10,n_jobs=12)\n",
    "        # print type(y_predict)\n",
    "        # y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=-1,method='predict_proba')\n",
    "        # predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "        # predict_save=np.array(predict_save).T\n",
    "        # pd.DataFrame(predict_save).to_csv('/home02/chenhuangrong/blending_files/frequency_predict_%d_gram.csv'%(gram),header=None,index=False)\n",
    "        ROC_AUC_area=\"%0.4f\"%cross_val_score(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=-1).mean()\n",
    "        ACC=metrics.accuracy_score(Y,y_predict)\n",
    "        precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "        F1_Score=metrics.f1_score(Y, y_predict)\n",
    "        F_measure=F1_Score\n",
    "        MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "        pos=TP+FN\n",
    "        neg=FP+TN\n",
    "        savedata=[[['svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "        print savedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
