{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "inputname=\"human\"\n",
    "outputname=\"human_knn_all\"\n",
    "path=\"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(path):\n",
    "    '''\n",
    "    used for load fasta data and transformd into numpy.array format\n",
    "    '''\n",
    "    fh=open(m6a_benchmark_dataset)\n",
    "    seq=[]\n",
    "    for line in fh:\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line.replace('\\r','').replace('\\n',''))\n",
    "    fh.close()\n",
    "    matrix_data=np.array([list(e) for e in seq])\n",
    "    return matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Comparing_score(query_sequence,original_sequence):\n",
    "    \n",
    "    score=0\n",
    "    for index,data in enumerate(query_sequence):\n",
    "        if data==original_sequence[index]:\n",
    "            score=score+2\n",
    "        else:\n",
    "            score=score-1\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generating_one_column(matrix_data):\n",
    "    whole_comparison_score=[]\n",
    "    the_begin_of_index=len(matrix_data)/2\n",
    "    for index_1,data_1 in enumerate(matrix_data):\n",
    "        one_line_comparison_score=np.zeros(len(matrix_data))\n",
    "        mark_origin_label=np.zeros(len(matrix_data))\n",
    "        for index_2,data_2 in enumerate(matrix_data):\n",
    "            if index_1!=index_2:\n",
    "                one_line_comparison_score[index_1]=-100\n",
    "                if index_2<the_begin_of_index:\n",
    "                    mark_origin_label[index_2]=1\n",
    "                one_line_comparison_score[index_2]=Comparing_score(data_1,data_2)\n",
    "        temp=[]\n",
    "        temp=[one_line_comparison_score,mark_origin_label]\n",
    "        whole_comparison_score.append(temp)\n",
    "    return whole_comparison_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generating_features(matrix_data,K_list):\n",
    "    matrix=generating_one_column(matrix_data)\n",
    "    print np.asarray(matrix).shape\n",
    "    whole_=[]\n",
    "    for index,K_data in enumerate(K_list):\n",
    "        line=[]\n",
    "        for data in matrix:\n",
    "            idx=np.argsort(data[0])[::-1]\n",
    "            idx=idx[xrange(K_data)]\n",
    "            data[1]=pd.DataFrame(data[1])\n",
    "            datas=data[1].iloc[idx]\n",
    "            datas=datas.values\n",
    "            line.append(sum(datas)/K_data)\n",
    "        whole_.append(line)\n",
    "    whole_=np.array(whole_).T\n",
    "    return whole_\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260, 2, 2260)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m6a_benchmark_dataset=path+inputname+\".fasta\"\n",
    "matrix_data=read_fasta_file(m6a_benchmark_dataset)\n",
    "final_feature_matrix=generating_features(matrix_data,xrange(1,101))\n",
    "pd.DataFrame(final_feature_matrix[0]).to_csv(path+outputname+'.csv',header=None,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_file_num: 2260\n",
      "first_file_length: 336\n",
      "second_file_num: 2260\n",
      "second_file_length: 4\n",
      "output_file_num: 2260\n",
      "output_file_len: 340\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "used to merge features\n",
    "\"\"\"\n",
    "RFH_=pd.read_csv(path+\"human_PseEIIP_fournucleotide_dinucleotide_trinucleotide.csv\",header=None,index_col=None)#sys.argv[1])\n",
    "RFH_=RFH_.values\n",
    "RFH_=pd.DataFrame(RFH_).astype(float)\n",
    "PseDNC_=pd.read_csv(path+\"human_PseEIIP_nucleotide.csv\",header=None,index_col=None)\n",
    "PseDNC_=pd.DataFrame(PseDNC_).astype(float)\n",
    "print \"first_file_num:\",len(RFH_)\n",
    "print \"first_file_length:\",len(RFH_.values[0])\n",
    "print \"second_file_num:\",len(PseDNC_)\n",
    "print \"second_file_length:\",len(PseDNC_.values[0])\n",
    "RFH_PseDNC=pd.concat([RFH_,PseDNC_],axis=1)\n",
    "print \"output_file_num:\",len(RFH_PseDNC)\n",
    "print \"output_file_len:\",len(RFH_PseDNC.values[0])\n",
    "scaler=MinMaxScaler()\n",
    "RFH_PseDNC=scaler.fit_transform(np.array(RFH_PseDNC))\n",
    "pd.DataFrame(RFH_PseDNC).to_csv(path+\"human_PseEIIP_fournucleotide_dinucleotide_trinucleotide_nucleotide.csv\",header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.         ...,  0.34693878  0.34343434  0.35      ]\n",
      " [ 1.          0.          0.5        ...,  0.51020408  0.50505051  0.5       ]\n",
      " [ 1.          0.          0.5        ...,  0.39795918  0.4040404   0.4       ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.32653061  0.32323232  0.32      ]\n",
      " [ 0.          0.          0.5        ...,  0.33673469  0.33333333  0.33      ]\n",
      " [ 0.          0.          0.         ...,  0.32653061  0.32323232  0.32      ]]\n",
      "the shape of data:(2260, 100)\n",
      "the shape of data and class:(2260, 101)\n",
      "mrmr complete \n",
      "the set is: [70, 71, 67, 68, 69, 65, 63, 72, 73, 74, 66, 76, 64, 57, 58, 54, 55, 56, 77, 62, 59, 60, 61, 75, 52, 95, 96, 92, 93, 94, 90, 88, 97, 98, 99, 91, 50, 89, 82, 83, 79, 80, 81, 78, 87, 84, 85, 86, 53, 1, 51, 19, 20, 16, 17, 18, 14, 21, 22, 23, 15, 25, 13, 26, 24, 44, 45, 41, 42, 43, 39, 37, 46, 47, 48, 40, 49, 38, 31, 32, 28, 29, 30, 27, 36, 33, 34, 35, 100, 12, 10, 11, 9, 7, 8, 5, 6, 3, 4, 2]\n",
      "[69]\n",
      "the best C and gamma are: 0.25 0.793700525984\n",
      "accuracy:  0.812389380531\n",
      "[69, 70]\n",
      "the best C and gamma are: 0.25 1.78179743628\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66]\n",
      "the best C and gamma are: 0.561231024155 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67]\n",
      "the best C and gamma are: 14.2543794902 0.157490131237\n",
      "accuracy:  0.816814159292\n",
      "[69, 70, 66, 67, 68]\n",
      "the best C and gamma are: 0.25 0.157490131237\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62]\n",
      "the best C and gamma are: 0.25 0.793700525984\n",
      "accuracy:  0.812389380531\n",
      "[69, 70, 66, 67, 68, 64, 62, 71]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72]\n",
      "the best C and gamma are: 0.25 0.353553390593\n",
      "accuracy:  0.811946902655\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73]\n",
      "the best C and gamma are: 0.561231024155 0.03125\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63]\n",
      "the best C and gamma are: 0.561231024155 0.157490131237\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56]\n",
      "the best C and gamma are: 0.561231024155 0.157490131237\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57]\n",
      "the best C and gamma are: 0.561231024155 0.157490131237\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53]\n",
      "the best C and gamma are: 14.2543794902 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54]\n",
      "the best C and gamma are: 2.82842712475 0.0701538780193\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55]\n",
      "the best C and gamma are: 0.561231024155 4.0\n",
      "accuracy:  0.809292035398\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76]\n",
      "the best C and gamma are: 2.82842712475 0.0701538780193\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61]\n",
      "the best C and gamma are: 14.2543794902 4.0\n",
      "accuracy:  0.771238938053\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58]\n",
      "the best C and gamma are: 0.25 4.0\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59]\n",
      "the best C and gamma are: 0.25 4.0\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60]\n",
      "the best C and gamma are: 0.25 4.0\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74]\n",
      "the best C and gamma are: 0.25 4.0\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51]\n",
      "the best C and gamma are: 0.25 4.0\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94]\n",
      "the best C and gamma are: 0.25 4.0\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95]\n",
      "the best C and gamma are: 1.25992104989 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93]\n",
      "the best C and gamma are: 0.25 0.157490131237\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89]\n",
      "the best C and gamma are: 0.25 0.157490131237\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87]\n",
      "the best C and gamma are: 0.25 0.157490131237\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19]\n",
      "the best C and gamma are: 0.25 0.157490131237\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15]\n",
      "the best C and gamma are: 2.82842712475 4.0\n",
      "accuracy:  0.792477876106\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16]\n",
      "the best C and gamma are: 2.82842712475 4.0\n",
      "accuracy:  0.792477876106\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17]\n",
      "the best C and gamma are: 2.82842712475 4.0\n",
      "accuracy:  0.792477876106\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13]\n",
      "the best C and gamma are: 32.0 0.793700525984\n",
      "accuracy:  0.782743362832\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20]\n",
      "the best C and gamma are: 6.34960420787 1.78179743628\n",
      "accuracy:  0.798672566372\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21]\n",
      "the best C and gamma are: 6.34960420787 1.78179743628\n",
      "accuracy:  0.798672566372\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22]\n",
      "the best C and gamma are: 14.2543794902 0.793700525984\n",
      "accuracy:  0.80796460177\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14]\n",
      "the best C and gamma are: 14.2543794902 0.157490131237\n",
      "accuracy:  0.816814159292\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24]\n",
      "the best C and gamma are: 14.2543794902 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12]\n",
      "the best C and gamma are: 14.2543794902 0.353553390593\n",
      "accuracy:  0.817699115044\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25]\n",
      "the best C and gamma are: 6.34960420787 0.353553390593\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23]\n",
      "the best C and gamma are: 0.561231024155 0.793700525984\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33]\n",
      "the best C and gamma are: 14.2543794902 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34]\n",
      "the best C and gamma are: 14.2543794902 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99]\n",
      "the best C and gamma are: 2.82842712475 0.157490131237\n",
      "accuracy:  0.813716814159\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11]\n",
      "the best C and gamma are: 6.34960420787 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9]\n",
      "the best C and gamma are: 6.34960420787 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10]\n",
      "the best C and gamma are: 14.2543794902 0.353553390593\n",
      "accuracy:  0.817699115044\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8]\n",
      "the best C and gamma are: 6.34960420787 0.793700525984\n",
      "accuracy:  0.815044247788\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6]\n",
      "the best C and gamma are: 2.82842712475 0.793700525984\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6, 7]\n",
      "the best C and gamma are: 2.82842712475 0.793700525984\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6, 7, 4]\n",
      "the best C and gamma are: 6.34960420787 0.353553390593\n",
      "accuracy:  0.815486725664\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6, 7, 4, 5]\n",
      "the best C and gamma are: 1.25992104989 1.78179743628\n",
      "accuracy:  0.814601769912\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6, 7, 4, 5, 2]\n",
      "the best C and gamma are: 2.82842712475 0.793700525984\n",
      "accuracy:  0.814159292035\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6, 7, 4, 5, 2, 3]\n",
      "the best C and gamma are: 1.25992104989 0.793700525984\n",
      "accuracy:  0.816371681416\n",
      "[69, 70, 66, 67, 68, 64, 62, 71, 72, 73, 65, 75, 63, 56, 57, 53, 54, 55, 76, 61, 58, 59, 60, 74, 51, 94, 95, 91, 92, 93, 89, 87, 96, 97, 98, 90, 49, 88, 81, 82, 78, 79, 80, 77, 86, 83, 84, 85, 52, 0, 50, 18, 19, 15, 16, 17, 13, 20, 21, 22, 14, 24, 12, 25, 23, 43, 44, 40, 41, 42, 38, 36, 45, 46, 47, 39, 48, 37, 30, 31, 27, 28, 29, 26, 35, 32, 33, 34, 99, 11, 9, 10, 8, 6, 7, 4, 5, 2, 3, 1]\n",
      "the best C and gamma are: 14.2543794902 0.353553390593\n",
      "accuracy:  0.817699115044\n",
      "[[['SVMC:14.2543794902gamma:0.353553390593', 0.81769911504424775, 0.9006696428571429, 0.7141592920353982, 0.7141592920353982, 0.9212389380530973, 0.8111173452685142, 0.79664363277393879, 0.79664363277393879, 0.6494762197920787, 0.81769911504424775, 807.0, 323.0, 89.0, 1041.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "\"\"\"\n",
    "    十折交叉验证 + mrmr\n",
    "\"\"\"\n",
    "classifier=\"SVM\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "outputpath=path+outputname+\"_output.csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "row=Y.shape[0]\n",
    "Y1=Y.reshape(row,1)\n",
    "#concatenate class and data\n",
    "full_csv_with_class=np.concatenate([Y1,X],axis=1)\n",
    "print full_csv_with_class\n",
    "\n",
    "#print the results of original csv data and final full data\n",
    "print \"the shape of data:\"+str(X.shape)\n",
    "print \"the shape of data and class:\"+str(full_csv_with_class.shape)\n",
    "\n",
    "#generating virtual headers\n",
    "columns=[\"class\"]\n",
    "columns_numbers=np.arange(full_csv_with_class.shape[1]-1)\n",
    "columns.extend(columns_numbers)\n",
    "\n",
    "# Write data into files\n",
    "csvFile2 = open(outputpath,'w') \n",
    "writer = csv.writer(csvFile2)\n",
    "m = len(full_csv_with_class)\n",
    "writer.writerow(columns)\n",
    "for i in range(m):\n",
    "    writer.writerow(full_csv_with_class[i])\n",
    "csvFile2.close()\n",
    "\n",
    "os.system(\"./mRMR/mrmr -i \"+outputpath+\" -n \"+str(full_csv_with_class.shape[1]-1)+\" >mRMR/\"+outputname+\"_output.mrmrout\")\n",
    "print \"mrmr complete \"\n",
    "location_mark=0\n",
    "final_set=[]\n",
    "fn=open(\"mRMR/\"+outputname+\"_output.mrmrout\",'r')\n",
    "for line in fn.readlines():\n",
    "    if line.strip() ==\"\":\n",
    "        location_mark=0\n",
    "    if location_mark==1 and line.split()[1]!=\"Fea\":\n",
    "         final_set.append(int(line.split()[1]))\n",
    "    if re.findall(r\"mRMR\",line) and re.findall(r\"feature\",line):\n",
    "        location_mark=1\n",
    "print \"the set is:\",final_set\n",
    "select_list=[]\n",
    "precision_copy=0\n",
    "recall_copy=0\n",
    "SN_copy=0\n",
    "SP_copy=0\n",
    "GM_copy=0\n",
    "TP_copy=0\n",
    "TN_copy=0\n",
    "FP_copy=0\n",
    "FN_copy=0\n",
    "ACC_copy=0\n",
    "F1_Score_copy=0\n",
    "F_measure_copy=0\n",
    "MCC_copy=0\n",
    "pos_copy=0\n",
    "neg_copy=0\n",
    "ROC_AUC_area_copy=[]\n",
    "y_pred_prob_copy=[]\n",
    "y_pred_copy=[]\n",
    "for j_num in final_set:\n",
    "    select_list.append(j_num-1)\n",
    "    print select_list\n",
    "    X_2=pd.DataFrame(X).iloc[:,select_list]\n",
    "    svc = svm.SVC()\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_2, Y)\n",
    "    C=clf.best_params_['C']\n",
    "    # joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "    # print clf.best_score_\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print \"the best C and gamma are:\",C,gamma\n",
    "    y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=12)\n",
    "    ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "    y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "    predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "    predict_save=np.array(predict_save).T\n",
    "    pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict_output.csv',header=None,index=False)\n",
    "    ACC=metrics.accuracy_score(Y,y_predict)\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "    F1_Score=metrics.f1_score(Y, y_predict)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    print \"accuracy: \",ACC\n",
    "    if ACC_copy<ACC:\n",
    "        ACC_copy=ACC\n",
    "        precision_copy=precision\n",
    "        recall_copy=recall\n",
    "        SN_copy=SN\n",
    "        SP_copy=SP\n",
    "        GM_copy=GM\n",
    "        TP_copy=TP\n",
    "        TN_copy=TN\n",
    "        FP_copy=FP\n",
    "        FN_copy=FN\n",
    "        ACC_copy=ACC\n",
    "        F1_Score_copy=F1_Score\n",
    "        F_measure_copy=F_measure\n",
    "        MCC_copy=MCC\n",
    "        ROC_AUC_area_copy=ROC_AUC_area\n",
    "        pos_copy=pos\n",
    "        neg_copy=neg\n",
    "        y_pred_prob_copy=y_predict_prob\n",
    "        y_pred_copy=y_predict\n",
    "savedata=[[[classifier+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_copy,precision_copy, recall_copy,SN_copy, SP_copy, GM_copy,F_measure_copy,F1_Score_copy,MCC_copy,ROC_AUC_area_copy,\n",
    "            TP_copy,FN_copy,FP_copy,TN_copy,pos_copy,neg_copy]]]\n",
    "print savedata\n",
    "print X_2.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X_2.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'output.xls')\n",
    "    # y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "    # Y=pd.DataFrame(Y)    \n",
    "    # y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "    # y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "    # pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "    # y_predict=pd.DataFrame(y_predict)\n",
    "    # y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "    # pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\n",
      "the best C and gamma are: 0.25 1.78179743628\n",
      "accuracy:  0.815486725664\n",
      "[98, 97]\n",
      "the best C and gamma are: 1.25992104989 4.0\n",
      "accuracy:  0.808407079646\n",
      "[98, 97, 96]\n",
      "the best C and gamma are: 14.2543794902 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95]\n",
      "the best C and gamma are: 6.34960420787 0.0701538780193\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94]\n",
      "the best C and gamma are: 1.25992104989 0.157490131237\n",
      "accuracy:  0.81592920354\n",
      "[98, 97, 96, 95, 94, 93]\n",
      "the best C and gamma are: 2.82842712475 0.157490131237\n",
      "accuracy:  0.813716814159\n",
      "[98, 97, 96, 95, 94, 93, 92]\n",
      "the best C and gamma are: 14.2543794902 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91]\n",
      "the best C and gamma are: 1.25992104989 0.03125\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88]\n",
      "the best C and gamma are: 6.34960420787 0.353553390593\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85]\n",
      "the best C and gamma are: 2.82842712475 0.353553390593\n",
      "accuracy:  0.817256637168\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82]\n",
      "the best C and gamma are: 6.34960420787 0.157490131237\n",
      "accuracy:  0.813716814159\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79]\n",
      "the best C and gamma are: 14.2543794902 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78]\n",
      "the best C and gamma are: 0.561231024155 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84]\n",
      "the best C and gamma are: 1.25992104989 0.03125\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73]\n",
      "the best C and gamma are: 1.25992104989 0.03125\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76]\n",
      "the best C and gamma are: 0.561231024155 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75]\n",
      "the best C and gamma are: 0.561231024155 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71]\n",
      "the best C and gamma are: 1.25992104989 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68]\n",
      "the best C and gamma are: 0.25 0.793700525984\n",
      "accuracy:  0.812389380531\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67]\n",
      "the best C and gamma are: 2.82842712475 0.03125\n",
      "accuracy:  0.81592920354\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66]\n",
      "the best C and gamma are: 6.34960420787 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70]\n",
      "the best C and gamma are: 1.25992104989 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69]\n",
      "the best C and gamma are: 0.561231024155 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65]\n",
      "the best C and gamma are: 0.561231024155 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64]\n",
      "the best C and gamma are: 0.25 0.0701538780193\n",
      "accuracy:  0.815044247788\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63]\n",
      "the best C and gamma are: 0.25 0.157490131237\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62]\n",
      "the best C and gamma are: 14.2543794902 1.78179743628\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61]\n",
      "the best C and gamma are: 6.34960420787 1.78179743628\n",
      "accuracy:  0.798672566372\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60]\n",
      "the best C and gamma are: 6.34960420787 1.78179743628\n",
      "accuracy:  0.798672566372\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55]\n",
      "the best C and gamma are: 32.0 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58]\n",
      "the best C and gamma are: 6.34960420787 4.0\n",
      "accuracy:  0.775221238938\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54]\n",
      "the best C and gamma are: 14.2543794902 1.78179743628\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45]\n",
      "the best C and gamma are: 0.25 0.03125\n",
      "accuracy:  0.811061946903\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44]\n",
      "the best C and gamma are: 14.2543794902 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41]\n",
      "the best C and gamma are: 14.2543794902 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39]\n",
      "the best C and gamma are: 14.2543794902 4.0\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37]\n",
      "the best C and gamma are: 32.0 1.78179743628\n",
      "accuracy:  0.758849557522\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35]\n",
      "the best C and gamma are: 14.2543794902 1.78179743628\n",
      "accuracy:  0.771238938053\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33]\n",
      "the best C and gamma are: 32.0 0.793700525984\n",
      "accuracy:  0.782743362832\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31]\n",
      "the best C and gamma are: 6.34960420787 0.0701538780193\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27]\n",
      "the best C and gamma are: 32.0 0.157490131237\n",
      "accuracy:  0.814601769912\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22]\n",
      "the best C and gamma are: 1.25992104989 0.793700525984\n",
      "accuracy:  0.816371681416\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19]\n",
      "the best C and gamma are: 32.0 0.157490131237\n",
      "accuracy:  0.814601769912\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13]\n",
      "the best C and gamma are: 32.0 0.0701538780193\n",
      "accuracy:  0.814159292035\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12]\n",
      "the best C and gamma are: 6.34960420787 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11]\n",
      "the best C and gamma are: 14.2543794902 0.793700525984\n",
      "accuracy:  0.80796460177\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9]\n",
      "the best C and gamma are: 6.34960420787 1.78179743628\n",
      "accuracy:  0.798672566372\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8]\n",
      "the best C and gamma are: 14.2543794902 0.793700525984\n",
      "accuracy:  0.80796460177\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7]\n",
      "the best C and gamma are: 14.2543794902 0.793700525984\n",
      "accuracy:  0.80796460177\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6]\n",
      "the best C and gamma are: 0.561231024155 4.0\n",
      "accuracy:  0.809292035398\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5]\n",
      "the best C and gamma are: 32.0 0.03125\n",
      "accuracy:  0.814601769912\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]\n",
      "the best C and gamma are: 1.25992104989 0.793700525984\n",
      "accuracy:  0.816371681416\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]\n",
      "the best C and gamma are: 1.25992104989 0.793700525984\n",
      "accuracy:  0.816371681416\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
      "the best C and gamma are: 32.0 0.353553390593\n",
      "accuracy:  0.810619469027\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
      "the best C and gamma are: 1.25992104989 0.793700525984\n",
      "accuracy:  0.816371681416\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "the best C and gamma are: 6.34960420787 0.353553390593\n",
      "accuracy:  0.815486725664\n",
      "[98, 97, 96, 95, 94, 93, 92, 91, 89, 90, 88, 87, 86, 85, 82, 79, 80, 83, 81, 78, 84, 77, 73, 76, 75, 74, 72, 71, 68, 67, 66, 70, 69, 65, 64, 63, 62, 61, 60, 57, 59, 56, 55, 58, 54, 53, 52, 51, 49, 48, 50, 47, 46, 45, 44, 40, 43, 42, 41, 39, 38, 36, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -1]\n",
      "the best C and gamma are: 14.2543794902 0.353553390593\n",
      "accuracy:  0.817699115044\n",
      "[[['SVMC:14.2543794902gamma:0.353553390593', 0.81769911504424775, 0.9006696428571429, 0.7141592920353982, 0.7141592920353982, 0.9212389380530973, 0.8111173452685142, 0.79664363277393879, 0.79664363277393879, 0.6494762197920787, 0.81769911504424775, 807.0, 323.0, 89.0, 1041.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from sklearn.feature_selection import  f_classif\n",
    "import re\n",
    "\"\"\"\n",
    "    十折交叉验证 + f-score\n",
    "\"\"\"\n",
    "classifier=\"SVM\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "\n",
    "F, pval = f_classif(X, Y)\n",
    "idx = np.argsort(F)\n",
    "Selected_list_=idx[::-1]\n",
    "\n",
    "select_list=[]\n",
    "precision_copy=0\n",
    "recall_copy=0\n",
    "SN_copy=0\n",
    "SP_copy=0\n",
    "GM_copy=0\n",
    "TP_copy=0\n",
    "TN_copy=0\n",
    "FP_copy=0\n",
    "FN_copy=0\n",
    "ACC_copy=0\n",
    "F1_Score_copy=0\n",
    "F_measure_copy=0\n",
    "MCC_copy=0\n",
    "pos_copy=0\n",
    "neg_copy=0\n",
    "ROC_AUC_area_copy=[]\n",
    "y_pred_prob_copy=[]\n",
    "y_pred_copy=[]\n",
    "for j_num in Selected_list_:\n",
    "    select_list.append(j_num-1)\n",
    "    print select_list\n",
    "    X_2=pd.DataFrame(X).iloc[:,select_list]\n",
    "    svc = svm.SVC()\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_2, Y)\n",
    "    C=clf.best_params_['C']\n",
    "    # joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "    # print clf.best_score_\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print \"the best C and gamma are:\",C,gamma\n",
    "    y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=12)\n",
    "    ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "    y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "    predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "    predict_save=np.array(predict_save).T\n",
    "    pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict_output_fscore.csv',header=None,index=False)\n",
    "    ACC=metrics.accuracy_score(Y,y_predict)\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "    F1_Score=metrics.f1_score(Y, y_predict)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    print \"accuracy: \",ACC\n",
    "    if ACC_copy<ACC:\n",
    "        ACC_copy=ACC\n",
    "        precision_copy=precision\n",
    "        recall_copy=recall\n",
    "        SN_copy=SN\n",
    "        SP_copy=SP\n",
    "        GM_copy=GM\n",
    "        TP_copy=TP\n",
    "        TN_copy=TN\n",
    "        FP_copy=FP\n",
    "        FN_copy=FN\n",
    "        ACC_copy=ACC\n",
    "        F1_Score_copy=F1_Score\n",
    "        F_measure_copy=F_measure\n",
    "        MCC_copy=MCC\n",
    "        ROC_AUC_area_copy=ROC_AUC_area\n",
    "        pos_copy=pos\n",
    "        neg_copy=neg\n",
    "        y_pred_prob_copy=y_predict_prob\n",
    "        y_pred_copy=y_predict\n",
    "savedata=[[[classifier+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_copy,precision_copy, recall_copy,SN_copy, SP_copy, GM_copy,F_measure_copy,F1_Score_copy,MCC_copy,ROC_AUC_area_copy,\n",
    "            TP_copy,FN_copy,FP_copy,TN_copy,pos_copy,neg_copy]]]\n",
    "print savedata\n",
    "print X_2.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X_2.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'output_fscore.xls')\n",
    "    # y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "    # Y=pd.DataFrame(Y)    \n",
    "    # y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "    # y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "    # pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "    # y_predict=pd.DataFrame(y_predict)\n",
    "    # y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "    # pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 32.0 gamma: 1.78179743628\n",
      "0.83185840708\n",
      "ACC_all: 0.83185840708\n",
      "c: 6.34960420787 gamma: 4.0\n",
      "0.836283185841\n",
      "ACC_all: 1.66814159292\n",
      "c: 32.0 gamma: 1.78179743628\n",
      "0.840707964602\n",
      "ACC_all: 2.50884955752\n",
      "c: 6.34960420787 gamma: 4.0\n",
      "0.840707964602\n",
      "ACC_all: 3.34955752212\n",
      "c: 6.34960420787 gamma: 4.0\n",
      "0.827433628319\n",
      "ACC_all: 4.17699115044\n",
      "c: 2.82842712475 gamma: 4.0\n",
      "0.827433628319\n",
      "ACC_all: 5.00442477876\n",
      "c: 32.0 gamma: 0.03125\n",
      "0.774336283186\n",
      "ACC_all: 5.77876106195\n",
      "c: 14.2543794902 gamma: 4.0\n",
      "0.836283185841\n",
      "ACC_all: 6.61504424779\n",
      "c: 2.82842712475 gamma: 4.0\n",
      "0.849557522124\n",
      "ACC_all: 7.46460176991\n",
      "c: 6.34960420787 gamma: 0.353553390593\n",
      "0.845132743363\n",
      "ACC_all: 8.30973451327\n",
      "['20', '\\xe6\\xad\\xa3\\xef\\xbc\\x9a1130.0\\xe8\\xb4\\x9f\\xef\\xbc\\x9a1130.0', 'svmC:6.34960420787gamma:0.353553390593', 0.83097345132743372, 0.929620896040122, 0.7168141592920354, 0.7168141592920354, 0.9451327433628318, 0.8226822953930515, 0.80871204823163612, 0.80871204823163612, 0.68060071085008533, 0.87162581251468407, 810.0, 320.0, 62.0, 1068.0]\n"
     ]
    }
   ],
   "source": [
    "final_out_to_excel=[]\n",
    "row0 = [u'特征集', u'样本个数', u'分类器', u'Accuracy', u'Precision', u'Recall', u'SN', u'SP',\n",
    "                u'Gm', u'F_measure', u'F_score', u'MCC', u'ROC曲线面积', u'tp', u'fn', u'fp', u'tn']\n",
    "final_out_to_excel.append(row0) #above was used to generate xlsx format Excel file\n",
    "RNA_code='ACGU' \n",
    "interval=3 # RNA_code and interval used mix used to generate AAA AAC AAG ...\n",
    "division_num=10\n",
    "divided_num=np.float(division_num)# ten fold so the result should divided by ten\n",
    "\n",
    "\n",
    "# seq=[e.replace('U','A') for e in seq]\n",
    "# seq=[e.replace('G','C') for e in seq]\n",
    "seq=pd.read_csv(path+name+'.csv',header=None,index_col=False)\n",
    "seq=seq.values\n",
    "\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "\n",
    "\n",
    "\n",
    "#define variable to save data which will be saved later --- begining\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "#define variable to save data which will be saved later --- end\n",
    "\n",
    "\n",
    "#shuffle the data of positive and negative begining\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  # positive and negative samples will be shuffled \n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "#shuffle the data of positive and negative end\n",
    "\n",
    "\n",
    "    #generate train and test data begining\n",
    "    X_train = np.array(positive_negative_x_train)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(X_train) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(X_train) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(positive_negative_y_train)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(X_test) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(X_test) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test = np.array(Y_test)\n",
    "    #generate train and test data end\n",
    "\n",
    "    \n",
    "    # training model and optimized parameters of C and gamma begining\n",
    "    svc = svm.SVC(probability=True)\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # training model and optimized parameters of C and gamma end\n",
    "    \n",
    "    \n",
    "    #print best C and gamma begining\n",
    "    C=clf.best_params_['C']\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print 'c:',C,'gamma:',gamma\n",
    "    #print best C and gamma end\n",
    "    \n",
    "    \n",
    "    #getting predict probability and predict label begining\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    #getting predict probability and predict label begining\n",
    "\n",
    "    #the process of generating  usefule data begining\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "    #the process of generating  usefule data end\n",
    "    \n",
    "#the process of save  data to disk begining   \n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "# pd.DataFrame(np.matrix(all_y).T).to_csv('/home02/chenhuangrong/PseEIIP%d.csv'%select_num,header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[str(X_train.shape[1]),\"正：\"+str(pos_all)+'负：'+str(neg_all),'svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all]\n",
    "final_out_to_excel.append(savedata)\n",
    "\n",
    "print savedata\n",
    "pd.DataFrame(final_out_to_excel).to_excel('/home02/chenhuangrong/'+name+'.xlsx',sheet_name=\"independent_test\",index=False,header=False)\n",
    "#the process of save  data to disk end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['SVMC:2.58536929514gamma:0.462937356144', 0.82035398230088497, 0.9031180400890868, 0.7176991150442478, 0.7176991150442478, 0.9230088495575222, 0.8139057896989325, 0.79980276134122286, 0.79980276134122286, 0.65465402754243518, 0.82035398230088497, 811.0, 319.0, 87.0, 1043.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"SVM\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "svc = svm.SVC()\n",
    "parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,28)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,28))}\n",
    "clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "C=clf.best_params_['C']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "gamma=clf.best_params_['gamma']\n",
    "y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['GBDTn_estimators:68max_depth:3min_samples_split:300min_samples_leaf:100', 0.81327433628318579, 0.890728476821192, 0.7141592920353982, 0.7141592920353982, 0.9123893805309734, 0.8072120874098798, 0.79273084479371325, 0.79273084479371325, 0.63923394144070123, 0.81327433628318579, 807.0, 323.0, 99.0, 1031.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation GBDT\n",
    "\"\"\"\n",
    "classifier=\"GBDT\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "GBDT = GradientBoostingClassifier(learning_rate=0.1,min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "clf = GridSearchCV(GBDT, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_estimators=clf.best_params_['n_estimators']\n",
    "max_depth=clf.best_params_['max_depth']\n",
    "min_samples_split=clf.best_params_['min_samples_split']\n",
    "min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(GradientBoostingClassifier(n_estimators=n_estimators,learning_rate=0.1,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(GradientBoostingClassifier(n_estimators=n_estimators,learning_rate=0.1,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf),ACC,precision, recall,SN, SP,\n",
    "            GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['RFn_estimators:10max_depth:13min_samples_split:100min_samples_leaf:80', 0.80796460176991147, 0.8849557522123894, 0.7079646017699115, 0.7079646017699115, 0.9079646017699115, 0.8017523294092831, 0.7866273352999017, 0.7866273352999017, 0.62863011097975363, 0.80796460176991147, 800.0, 330.0, 104.0, 1026.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation RF\n",
    "\"\"\"\n",
    "classifier=\"RF\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y) \n",
    "RF = RandomForestClassifier(min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "clf = GridSearchCV(RF, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_estimators=clf.best_params_['n_estimators']\n",
    "max_depth=clf.best_params_['max_depth']\n",
    "min_samples_split=clf.best_params_['min_samples_split']\n",
    "min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(RandomForestClassifier(n_estimators=n_estimators,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(RandomForestClassifier(n_estimators=n_estimators,min_samples_split=min_samples_split,\n",
    "                                                       min_samples_leaf=min_samples_leaf,max_depth=max_depth,max_features='sqrt'),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf),ACC,precision, recall,SN, SP,\n",
    "            GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['NB', 0.81238938053097343, 0.8771367521367521, 0.7265486725663717, 0.7265486725663717, 0.8982300884955752, 0.8078414933980766, 0.7947725072604066, 0.7947725072604066, 0.63419495678799576, 0.81238938053097343, 821.0, 309.0, 115.0, 1015.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation NB\n",
    "\"\"\"\n",
    "classifier=\"NB\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(GaussianNB(),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(GaussianNB(),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier,ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['LRC:1.0', 0.81150442477876106, 0.8430799220272904, 0.7654867256637168, 0.7654867256637168, 0.8575221238938053, 0.8101986193543316, 0.80241187384044521, 0.80241187384044521, 0.62566433426311097, 0.81150442477876106, 865.0, 265.0, 161.0, 969.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"LR\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "logisReg = LogisticRegression()\n",
    "C_range = 10.0 ** np.arange(-4,3,1)\n",
    "grid_parame = dict(C=C_range)\n",
    "clf = GridSearchCV(logisReg, grid_parame, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "C=clf.best_params_['C']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "\n",
    "y_predict=cross_val_predict(LogisticRegression(C=C),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(LogisticRegression(C=C),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"C:\"+str(C),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['KNNn_neighbors:8weights:uniformalgorithm:autoleaf_size:1', 0.80752212389380529, 0.888268156424581, 0.7035398230088495, 0.7035398230088495, 0.911504424778761, 0.8007993891610012, 0.7851851851851851, 0.7851851851851851, 0.62879193285270096, 0.80752212389380529, 795.0, 335.0, 100.0, 1030.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"KNN\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "knn = KNeighborsClassifier()\n",
    "#设置k的范围\n",
    "k_range = list(range(1,10))\n",
    "leaf_range = list(range(1,2))\n",
    "weight_options = ['uniform','distance']\n",
    "algorithm_options = ['auto','ball_tree','kd_tree','brute']\n",
    "param_gridknn = dict(n_neighbors = k_range,weights = weight_options,algorithm=algorithm_options,leaf_size=leaf_range)\n",
    "clf = GridSearchCV(knn, param_gridknn, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_neighbors=clf.best_params_['n_neighbors']\n",
    "weights=clf.best_params_['weights']\n",
    "algorithm=clf.best_params_['algorithm']\n",
    "leaf_size=clf.best_params_['leaf_size']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "\n",
    "y_predict=cross_val_predict(KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,algorithm=algorithm,leaf_size=leaf_size),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,algorithm=algorithm,leaf_size=leaf_size),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_neighbors:\"+str(n_neighbors)+\"weights:\"+str(weights)+\"algorithm:\"+str(algorithm)+\"leaf_size:\"+str(leaf_size),\n",
    "            ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['XGBoostn_estimators:7max_depth:4learning_rate:0.4subsample:0.9', 0.82168141592920352, 0.8981380065717415, 0.7256637168141593, 0.7256637168141593, 0.9176991150442478, 0.8160520514894094, 0.80274106705824766, 0.80274106705824766, 0.65556419285543932, 0.82168141592920352, 820.0, 310.0, 93.0, 1037.0, 1130.0, 1130.0]]]\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation XGBoost\n",
    "\"\"\"\n",
    "classifier=\"XGBoost\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "parameters = [{'n_estimators':range(1,10,1),\n",
    "                      'max_depth':range(2,10),\n",
    "                      'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "                      'subsample':[0.75,0.8,0.85,0.9]\n",
    "                      }]\n",
    "clf = GridSearchCV(XGBClassifier(), parameters, cv=10, n_jobs=1, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "n_estimators=clf.best_params_['n_estimators']\n",
    "max_depth=clf.best_params_['max_depth']\n",
    "learning_rate=clf.best_params_['learning_rate']\n",
    "subsample=clf.best_params_['subsample']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "y_predict=cross_val_predict(XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,\n",
    "                                                       subsample=subsample,max_depth=max_depth),X,Y,cv=10,n_jobs=1)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,\n",
    "                                                       subsample=subsample,max_depth=max_depth),X,Y,cv=10,n_jobs=1,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"learning_rate:\"+str(learning_rate)+\"subsample:\"+str(subsample),ACC,precision, recall,SN, SP,\n",
    "            GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
