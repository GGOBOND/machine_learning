{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "inputname=\"human.fasta\"\n",
    "outputname=\"human_PC_PseDNC_test\"\n",
    "path=\"data/\"\n",
    "propertyname=\"physical_chemical_properties_4.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_from_original_sequence(w,Lamda,num,pythysicalchemical_indices):\n",
    "    phisical_chemical_proporties=pd.read_csv(path+propertyname,header=None,index_col=None)\n",
    "    m6a_sequence=open(path+inputname)\n",
    "    DNC_key=phisical_chemical_proporties.values[:,0]\n",
    "    # DNC_key=np.array(['AA','AC','AG','AU','CA','CC','CG','CU','GA','GC','GG','GU','UA','UC','UG','UU'])\n",
    "    DNC_value=phisical_chemical_proporties.values[:,num]\n",
    "    DNC_value=np.array(DNC_value).T\n",
    "    DNC_value_scale=[[]]*len(DNC_value)\n",
    "    for i in xrange(len(DNC_value)):\n",
    "        average_=sum(DNC_value[i]*1.0/len(DNC_value[i]))\n",
    "        std_=np.std(DNC_value[i],ddof=1)\n",
    "        DNC_value_scale[i]=[round((e-average_)/std_,2) for e in DNC_value[i]]\n",
    "    DNC_value_scale=zip(*DNC_value_scale)\n",
    "    DNC_len=len(DNC_value_scale[0])\n",
    "    m6aseq=[]\n",
    "    for line in m6a_sequence:\n",
    "        if line.startswith('>'):\n",
    "            pass\n",
    "        else:\n",
    "            m6aseq.append(line.replace('\\n','').replace(\"\\r\",''))\n",
    "    result_value=[]\n",
    "    m6a_len=len(m6aseq[0])\n",
    "    m6a_num=len(m6aseq)\n",
    "    for m6a_line_index in xrange(m6a_num):\n",
    "        frequency=[0]*16\n",
    "        m6a_DNC_value=[[]]*(m6a_len-1)\n",
    "        for m6a_line_doublechar_index in xrange(m6a_len):\n",
    "            for DNC_index in xrange(16):\n",
    "                if m6aseq[m6a_line_index][m6a_line_doublechar_index:m6a_line_doublechar_index+2]==DNC_key[DNC_index]:\n",
    "                    m6a_DNC_value[m6a_line_doublechar_index]=DNC_value_scale[DNC_index]\n",
    "                    frequency[DNC_index]+=1\n",
    "        frequency=[e/float(sum(frequency)) for e in frequency]\n",
    "        p=sum((frequency))\n",
    "        #frequency=np.array(frequency)/float(sum(frequency))#(m6a_len-1)\n",
    "        one_line_value_with = 0.0\n",
    "        sita = [0] *  Lamda* pythysicalchemical_indices\n",
    "        for lambda_index in xrange(1, Lamda* pythysicalchemical_indices+ 1):\n",
    "            one_line_value_without_ = 0.0\n",
    "            head_value=(lambda_index-1)%pythysicalchemical_indices\n",
    "            for m6a_sequence_value_index in xrange(1, m6a_len - 3-(lambda_index-1)//pythysicalchemical_indices+1):    \n",
    "                temp = round((np.array(m6a_DNC_value[m6a_sequence_value_index - 1][head_value])+\n",
    "                                                             np.array(m6a_DNC_value[m6a_sequence_value_index ][head_value])),8)\n",
    "                one_line_value_without_ += temp\n",
    "            leng=(m6a_len - 3-(lambda_index-1)//pythysicalchemical_indices)\n",
    "            one_line_value_without_ = round(one_line_value_without_ /leng ,8)\n",
    "            sita[lambda_index - 1] = one_line_value_without_\n",
    "            one_line_value_with += one_line_value_without_\n",
    "        dim = [0] * (16 + Lamda* pythysicalchemical_indices)\n",
    "        for index in xrange(1, 16 +  Lamda* pythysicalchemical_indices+1):\n",
    "            if index <= 16:\n",
    "                dim[index - 1] = frequency[index - 1] / (1.0 + w * one_line_value_with)\n",
    "            else:\n",
    "                dim[index - 1] = w * sita[index - 17] / (1.0 + w * one_line_value_with)\n",
    "            dim[index-1]=round(dim[index-1],8)\n",
    "        result_value.append(dim)\n",
    "    pd.DataFrame(result_value).to_csv(path+outputname+str(w)+str(Lamda)+str(num)+\".csv\", header=None, index=None)\n",
    "    print \"savepath\",path+outputname+str(w)+str(Lamda)+str(num)+\".csv\"\n",
    "\n",
    "    m6a_sequence.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svm(w,lamda,num):\n",
    "    import time\n",
    "    startTime=time.time()\n",
    "    classifier=\"SVM\"\n",
    "    datapath =path+outputname+str(w)+str(lamda)+str(num)+\".csv\"\n",
    "    print \"datapath\",datapath\n",
    "    train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "    X = np.array(train_data)\n",
    "    Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "    Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "    Y.extend(Y2)\n",
    "    Y = np.array(Y)\n",
    "    svc = svm.SVC()\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X, Y)\n",
    "    C=clf.best_params_['C']\n",
    "    # joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "    # print clf.best_score_\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=12)\n",
    "    ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "    y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "    predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "    predict_save=np.array(predict_save).T\n",
    "    pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+str(w)+str(lamda)+str(num)+'_predict.csv',header=None,index=False)\n",
    "    ACC=metrics.accuracy_score(Y,y_predict)\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "    F1_Score=metrics.f1_score(Y, y_predict)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    savedata=[[[classifier+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "    print savedata\n",
    "    print X.shape[1]\n",
    "    easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+str(w)+str(lamda)+str(num)+'.xls')\n",
    "    endTime=time.time()\n",
    "    elapsedTime=endTime-startTime\n",
    "    print \"end\"\n",
    "    print \"elaspsed time:\",elapsedTime\n",
    "    return ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "0.07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-cd3c0b9146d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mextract_features_from_original_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#fetch features from original sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mACC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#construct a support vector machine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mACC\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mACC_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-b2e4ac15fb04>\u001b[0m in \u001b[0;36mextract_features_from_original_sequence\u001b[0;34m(w, Lamda, num, pythysicalchemical_indices)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm6a_sequence_value_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm6a_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_index\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpythysicalchemical_indices\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 temp = round((np.array(m6a_DNC_value[m6a_sequence_value_index - 1][head_value])+\n\u001b[0;32m---> 43\u001b[0;31m                                                              np.array(m6a_DNC_value[m6a_sequence_value_index ][head_value])),8)\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mone_line_value_without_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mleng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm6a_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_index\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpythysicalchemical_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "print \"start\"\n",
    "ACC_=0\n",
    "W=0\n",
    "Lambda=0\n",
    "for w in np.arange(0,1,0.1):\n",
    "    for lamda in xrange(1,6):\n",
    "        extract_features_from_original_sequence(w,lamda,list(np.arange(1,16)),15)#fetch features from original sequences\n",
    "        ACC=train_svm(w,lamda,list(np.arange(1,16)))#construct a support vector machine\n",
    "        if ACC>ACC_:\n",
    "            ACC_=ACC\n",
    "            W=w\n",
    "            Lambda=lamda\n",
    "print \"W,Lambda\",W,Lambda\n",
    "print \"ACC_\",ACC_\n",
    "save_list=[]\n",
    "save_index=[]\n",
    "for index in xrange(1,16):\n",
    "    extract_features_from_original_sequence(W,Lambda,[index],1)#fetch features from original sequences\n",
    "    ACC=train_svm(W,Lambda,[index])#construct a support vector machine\n",
    "    save_list.append(ACC)\n",
    "sorted_save_list=sorted(save_list)[::-1]\n",
    "for data in sorted_save_list:\n",
    "    save_index.append(save_list.index(data))\n",
    "print \"sorted_save_list\",sorted_save_list\n",
    "print \"save_index\",save_index\n",
    "number_list=[]\n",
    "temp_ACC=0\n",
    "for number in save_index:\n",
    "    number_list.append(number)\n",
    "    print \"number_list\"\n",
    "    extract_features_from_original_sequence(W,Lambda,number_list,len(number_list))#fetch features from original sequences\n",
    "    ACC=train_svm(W,Lambda,number_list)#construct a support vector machine\n",
    "    if ACC>=temp_ACC:\n",
    "        temp_ACC=ACC\n",
    "    else:\n",
    "        print \"W,Lambda,ACC\",W,Lambda,temp_ACC\n",
    "print \"number_list\",number_list\n",
    "ACC_=0\n",
    "W=0\n",
    "Lambda=0\n",
    "for w in np.arange(0,1,0.1):\n",
    "    for lamda in xrange(1,6):\n",
    "        extract_features_from_original_sequence(w,lamda,number_list,len(number_list))#fetch features from original sequences\n",
    "        ACC=train_svm(w,lamda,list(np.arange(1,16)))#construct a support vector machine\n",
    "        if ACC>ACC_:\n",
    "            ACC_=ACC\n",
    "            W=w\n",
    "            Lambda=lamda\n",
    "print \"W,lambda,ACC\",W,Lambda,ACC_\n",
    "print \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
