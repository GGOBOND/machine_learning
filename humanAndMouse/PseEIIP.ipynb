{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "path=\"data/\"\n",
    "inputname=\"human.fasta\"\n",
    "outputname=\"human_PseEIIP_fournucleotide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(path):\n",
    "    '''\n",
    "    used for load fasta data and transformd into numpy.array format\n",
    "    '''\n",
    "    fh=open(m6a_benchmark_dataset)\n",
    "    seq=[]\n",
    "    for line in fh:\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line.replace('\\r','').replace('\\n',''))\n",
    "    fh.close()\n",
    "    matrix_data=np.array([list(e) for e in seq])\n",
    "    return matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AthMethPre_extract_one_line(data_line):\n",
    "    '''\n",
    "    extract features from one line, such as one m6A sample\n",
    "    '''\n",
    "    beginning=0\n",
    "    end=len(data_line)-1\n",
    "    numbers=4\n",
    "    one_line_feature=[]\n",
    "    alphabet='AUCG'\n",
    "    matrix_three=[\"\".join(e) for e in itertools.product(alphabet, repeat=numbers)]# AAA AAU AAC ...\n",
    "    feature_three=np.zeros(int(pow(4,numbers)))\n",
    "    A=0.1260\n",
    "    U=0.1335\n",
    "    C=0.1340\n",
    "    G=0.0806\n",
    "    AUCG=[sum(e) for e in itertools.product([A,U,C,G], repeat=numbers)]# AAA AAU AAC ...\n",
    "    for index,data in enumerate(data_line):\n",
    "        if \"\".join(data_line[index:(index+numbers)]) in matrix_three and index <= end-numbers+1:\n",
    "            feature_three[matrix_three.index(\"\".join(data_line[index:(index+numbers)]))]+=1     \n",
    "    sum_three=np.sum(feature_three)\n",
    "    feature_three=feature_three/sum_three\n",
    "    feature_three=feature_three*AUCG\n",
    "    one_line_feature.extend(feature_three)\n",
    "    return one_line_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AthMethPre_feature_extraction(matrix_data):\n",
    "    final_feature_matrix=[AthMethPre_extract_one_line(e) for e in matrix_data]\n",
    "    return final_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "m6a_benchmark_dataset='data/human.fasta'\n",
    "matrix_data=read_fasta_file(m6a_benchmark_dataset)\n",
    "final_feature_matrix=AthMethPre_feature_extraction(matrix_data)\n",
    "pd.DataFrame(final_feature_matrix).to_csv(path+outputname+\".csv\",header=None,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['SVMC:32.0gamma:4.0', 0.81725663716814156, 0.8892508143322475, 0.7247787610619469, 0.7247787610619469, 0.9097345132743363, 0.8120075451781632, 0.79863481228668942, 0.79863481228668942, 0.64565281976364053, 0.81725663716814168, 819.0, 311.0, 102.0, 1028.0, 1130.0, 1130.0]]]\n",
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    cross validation\n",
    "\"\"\"\n",
    "classifier=\"SVM\"\n",
    "datapath =path+outputname+\".csv\"\n",
    "train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "X = np.array(train_data)\n",
    "Y = list(map(lambda x: 1, xrange(len(train_data) // 2)))\n",
    "Y2 = list(map(lambda x: 0, xrange(len(train_data) // 2)))\n",
    "Y.extend(Y2)\n",
    "Y = np.array(Y)\n",
    "svc = svm.SVC()\n",
    "parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "clf.fit(X, Y)\n",
    "C=clf.best_params_['C']\n",
    "# joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "# print clf.best_score_\n",
    "gamma=clf.best_params_['gamma']\n",
    "y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=10,n_jobs=12)\n",
    "ROC_AUC_area=metrics.roc_auc_score(Y, y_predict)\n",
    "y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,n_jobs=12,method='predict_proba')\n",
    "predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "predict_save=np.array(predict_save).T\n",
    "pd.DataFrame(predict_save).to_csv(path+outputname+\"_\"+classifier+'_predict.csv',header=None,index=False)\n",
    "ACC=metrics.accuracy_score(Y,y_predict)\n",
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "F1_Score=metrics.f1_score(Y, y_predict)\n",
    "F_measure=F1_Score\n",
    "MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "pos=TP+FN\n",
    "neg=FP+TN\n",
    "savedata=[[[classifier+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "print savedata\n",
    "print X.shape[1]\n",
    "easy_excel.save(classifier+\"_crossvalidation\",[str(X.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')\n",
    "# y_predict_proba=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=10,method=\"predict_proba\")\n",
    "# Y=pd.DataFrame(Y)    \n",
    "# y_predict_proba=pd.DataFrame(y_predict_proba)\n",
    "# y_predict_proba=pd.concat([Y,y_predict_proba],axis=1)\n",
    "# pd.DataFrame(y_predict_proba).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_label.csv',header=None,index=False)\n",
    "# y_predict=pd.DataFrame(y_predict)\n",
    "# y_predict_=pd.concat([Y,y_predict],axis=1)\n",
    "# pd.DataFrame(y_predict_).to_csv('/home02/chenhuangrong/RFH_ten_cross_validation_predict.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
