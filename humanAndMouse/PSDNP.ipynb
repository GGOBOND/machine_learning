{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "path=\"data/\"\n",
    "inputname=\"human.fasta\"\n",
    "outputname=\"human_PSDNP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   4   6   8  10  12  14  16  18 110]\n"
     ]
    }
   ],
   "source": [
    "b=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "a=[1,2,3,4,5,6,7,8,9,100]\n",
    "a=np.array(a)\n",
    "c=a+b\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation svm\n",
    "'''\n",
    "classifier=\"SVM\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    svc = svm.SVC(probability=True)\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,28)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,28))}\n",
    "#     parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-5,15,30)), 'gamma':map(lambda x:2**x,np.linspace(-15,5,30))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    C=clf.best_params_['C']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    \n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print 'c:',C,'gamma:',gamma\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[['svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(\"svm_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation GBDT\n",
    "'''\n",
    "classifier=\"GBDT\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    GBDT = GradientBoostingClassifier(learning_rate=0.1,min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "    parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "    clf = GridSearchCV(GBDT, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_estimators=clf.best_params_['n_estimators']\n",
    "    max_depth=clf.best_params_['max_depth']\n",
    "    min_samples_split=clf.best_params_['min_samples_split']\n",
    "    min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf)\n",
    "            ,ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation RF\n",
    "'''\n",
    "classifier=\"RF\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    RF = RandomForestClassifier(min_samples_split=300,min_samples_leaf=20,max_depth=8,max_features='sqrt')\n",
    "    parameters = {'n_estimators':range(10,120,1),'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200),'min_samples_leaf':range(60,101,10)}\n",
    "    clf = GridSearchCV(RF, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_estimators=clf.best_params_['n_estimators']\n",
    "    max_depth=clf.best_params_['max_depth']\n",
    "    min_samples_split=clf.best_params_['min_samples_split']\n",
    "    min_samples_leaf=clf.best_params_['min_samples_leaf']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"min_samples_split:\"+str(min_samples_split)+\"min_samples_leaf:\"+str(min_samples_leaf)\n",
    "            ,ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation NB\n",
    "'''\n",
    "classifier=\"NB\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    NB=GaussianNB()\n",
    "    NB.fit(X_train,Y_train)\n",
    "    y_pred=NB.predict(X_test)\n",
    "    y_pred_prob=NB.predict_proba(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier,ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation LR\n",
    "'''\n",
    "classifier=\"LR\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    \n",
    "    logisReg = LogisticRegression()\n",
    "    C_range = 10.0 ** np.arange(-4,3,1)\n",
    "    grid_parame = dict(C=C_range)\n",
    "    clf = GridSearchCV(logisReg, grid_parame, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    C=clf.best_params_['C']\n",
    "    y_pred=clf.predict(X_test)\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"C:\"+str(C),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation KNN\n",
    "'''\n",
    "classifier=\"KNN\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    knn = KNeighborsClassifier()\n",
    "    #设置k的范围\n",
    "    k_range = list(range(1,10))\n",
    "    leaf_range = list(range(1,2))\n",
    "    weight_options = ['uniform','distance']\n",
    "    algorithm_options = ['auto','ball_tree','kd_tree','brute']\n",
    "    param_gridknn = dict(n_neighbors = k_range,weights = weight_options,algorithm=algorithm_options,leaf_size=leaf_range)\n",
    "    clf = GridSearchCV(knn, param_gridknn, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_neighbors=clf.best_params_['n_neighbors']\n",
    "    weights=clf.best_params_['weights']\n",
    "    algorithm=clf.best_params_['algorithm']\n",
    "    leaf_size=clf.best_params_['leaf_size']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_neighbors:\"+str(n_neighbors)+\"weights:\"+str(weights)+\"algorithm:\"+str(algorithm)+\"leaf_size:\"+str(leaf_size),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cross validation XGBoost\n",
    "'''\n",
    "classifier=\"XGBoost\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "seq=[]\n",
    "m6a_2614_sequence=path+inputname\n",
    "RNA_code='ACGU'\n",
    "# k=4\n",
    "interval=2\n",
    "gap=1\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "\n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "# for interval in xrange(1,k+1):\n",
    "    final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_x_train))]\n",
    "    code_values=make_kmer_list(interval,RNA_code)\n",
    "    code_len=len(code_values)\n",
    "    positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval-gap*(interval-1))] for ii in xrange(code_len)]\n",
    "    for i,line_value in enumerate(positive_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0] \n",
    "                        \n",
    "                    if c_value==temp_value:\n",
    "                        positive_seq_value[p][j]+=1\n",
    "    positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1):\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                        negative_seq_value[p][j]+=1\n",
    "    negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "    for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "    y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval-gap*(interval-1))] for jj in xrange(len(positive_negative_y_train))]\n",
    "    for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "        for j,code_value in enumerate(line_value[0]):\n",
    "            if j<= len(line_value[0])-interval-1-gap*(interval-1) :\n",
    "                for p,c_value in enumerate(code_values):\n",
    "                    temp_value=np.array([y for x,y in enumerate(line_value[0][j:j+interval+gap*(interval-1)]) if x%(gap+1)==0])\n",
    "                    temp_value=[reduce(lambda x,y:x+y,temp_value)]\n",
    "                    temp_value=temp_value[0]\n",
    "                    if c_value==temp_value:\n",
    "                          y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "                            \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     print len(y_final_seq_value),len(y_final_seq_value[0]),y_final_seq_value\n",
    "#     break\n",
    "    X_train = np.array(final_seq_value)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(final_seq_value) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(final_seq_value) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(y_final_seq_value)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test  = np.array(Y_test)\n",
    "    parameters = [{'n_estimators':range(1,10,1),\n",
    "                      'max_depth':range(2,10),\n",
    "                      'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "                      'subsample':[0.75,0.8,0.85,0.9]\n",
    "                      }]\n",
    "    clf = GridSearchCV(XGBClassifier(), parameters, cv=10, n_jobs=1, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    n_estimators=clf.best_params_['n_estimators']\n",
    "    max_depth=clf.best_params_['max_depth']\n",
    "    learning_rate=clf.best_params_['learning_rate']\n",
    "    subsample=clf.best_params_['subsample']\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "    \n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv(path+outputname+\"_\"+classifier+\"_predict.csv\",header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[[[classifier+\"n_estimators:\"+str(n_estimators)+\"max_depth:\"+str(max_depth)+\"learning_rate:\"+str(learning_rate)+\"subsample:\"+str(subsample),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all,pos_all,neg_all]]]\n",
    "print savedata\n",
    "easy_excel.save(classifier+\"_independent_test\",[str(X_train.shape[1])],savedata,path+'cross_validation_'+classifier+\"_\"+outputname+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
